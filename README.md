# FastTrackAPI â€“ Projeto Prisma

[![Coverage](https://codecov.io/gh/SEU_USUARIO/FastTrackAPI---Projeto-Prisma/branch/main/graph/badge.svg)](https://codecov.io/gh/SEU_USUARIO/FastTrackAPI---Projeto-Prisma)
---------- coverage: platform win32, python 3.12.6-final-0 -----------
Name                                                Stmts   Miss  Cover   Missing
TOTAL                                                 863    107    88%

Required test coverage of 80% reached. Total coverage: 82.36%

Este repositÃ³rio faz parte de uma mentoria prÃ¡tica de backend com Python e FastAPI.  
O **Projeto Prisma** representa a construÃ§Ã£o de uma base sÃ³lida e estruturada, refletindo a clareza e a organizaÃ§Ã£o de um backend bem projetado.

A proposta do **FastTrackAPI** Ã© acelerar o aprendizado, explorando na prÃ¡tica os principais pilares do desenvolvimento backend moderno:

- Arquitetura de Software
- Boas PrÃ¡ticas de CÃ³digo
- SeguranÃ§a (JWT, OAuth2, controle de acesso)
- Versionamento com Git e GitHub
- Testes Automatizados com Pytest
- DevOps com Docker, Docker Compose e GitHub Actions
- Observabilidade (Logging e Monitoramento)
- IntegraÃ§Ã£o com Banco de Dados via SQLAlchemy + Alembic
- Cache com Redis e Background Tasks
- DocumentaÃ§Ã£o e Deploy

O projeto Ã© modular, versionado publicamente e busca simular um ambiente profissional, servindo como referÃªncia para estudos e futuros sistemas reais.

---

## ğŸ¯ Objetivo Geral

Desenvolver habilidades avanÃ§adas em desenvolvimento backend com Python utilizando o framework FastAPI, compreendendo arquitetura de software, seguranÃ§a, prÃ¡ticas modernas de DevOps, testes automatizados, observabilidade e documentaÃ§Ã£o, por meio da construÃ§Ã£o de um projeto prÃ¡tico hospedado no GitHub.

---

## ğŸ“Œ Objetivos EspecÃ­ficos Detalhados

- [ ] **Dominar os fundamentos e recursos avanÃ§ados do FastAPI**
  - [x] Criar rotas RESTful com mÃ©todos GET, POST, PUT, DELETE
  - [x] Utilizar `Depends` para injeÃ§Ã£o de dependÃªncias
  - [x] Validar dados de entrada e saÃ­da com Pydantic
  - [x] Utilizar tags, responses e exemplos para a documentaÃ§Ã£o automÃ¡tica
  - [ ] Implementar Background Tasks
  - [x] Trabalhar com WebSockets
  - [x] Fazer upload e download de arquivos

- [ ] **Aplicar arquitetura de software adequada para aplicaÃ§Ãµes backend**
  - [x] Organizar a aplicaÃ§Ã£o em camadas (router, service, repository, schema, model)
  - [ ] Aplicar princÃ­pios SOLID, DRY, KISS e YAGNI
  - [x] Criar dependÃªncias reutilizÃ¡veis e testÃ¡veis
  - [ ] Adotar um padrÃ£o de projeto para escalar o backend

- [ ] **Implementar boas prÃ¡ticas de seguranÃ§a no backend**
  - [x] Utilizar autenticaÃ§Ã£o com JWT
  - [x] Implementar autorizaÃ§Ã£o com escopos e permissÃµes
  - [x] Proteger rotas com `Depends` e lÃ³gica de verificaÃ§Ã£o
  - [x] Armazenar senhas com hash seguro (bcrypt, passlib)
  - [ ] Prevenir vulnerabilidades comuns (SQL Injection, XSS, etc)

- [ ] **Utilizar ferramentas e prÃ¡ticas de DevOps no fluxo de desenvolvimento**
  - [x] Utilizar Docker para empacotar a aplicaÃ§Ã£o
  - [x] Orquestrar serviÃ§os com Docker Compose (app, banco, redis)
  - [x] Criar pipelines de CI com GitHub Actions (teste e lint automÃ¡tico)
  - [ ] Rodar migrations de banco em containers (ex: Alembic via Compose)

- [x] **Gerenciar configuraÃ§Ãµes de forma segura e flexÃ­vel**
  - [x] Utilizar `.env` com Pydantic Settings
  - [x] Separar configuraÃ§Ãµes por ambiente (dev, prod, test)
  - [x] Garantir fallback seguro para variÃ¡veis obrigatÃ³rias

- [x] **Desenvolver testes automatizados**
  - [x] Criar testes unitÃ¡rios com `pytest`
  - [x] Implementar testes de integraÃ§Ã£o simulando requisiÃ§Ãµes reais
  - [x] Utilizar mocks para isolar dependÃªncias em testes
  - [x] Medir cobertura de cÃ³digo com `pytest-cov`

- [ ] **Adicionar observabilidade e monitoramento Ã  aplicaÃ§Ã£o**
  - [x] Adicionar logs estruturados com `loguru` ou `structlog`
  - [x] Criar middlewares para registrar requisiÃ§Ãµes/respostas
  - [ ] Monitorar erros e alertas (integraÃ§Ã£o futura com ferramentas externas)

- [x] **Documentar a API e o projeto de forma clara e profissional**
  - [x] Aproveitar documentaÃ§Ã£o automÃ¡tica do Swagger/OpenAPI
  - [x] Adicionar exemplos e descriÃ§Ãµes nos modelos Pydantic
  - [x] Manter um `README.md` atualizado e bem estruturado

- [ ] **Aprofundar o uso de banco de dados com SQLAlchemy**
  - [x] Criar modelos ORM com relacionamentos
  - [ ] Escrever queries mais avanÃ§adas (joins, agregaÃ§Ãµes)
  - [x] Implementar filtros e paginaÃ§Ã£o em endpoints
  - [x] Gerenciar migraÃ§Ãµes com Alembic

- [x] **Trabalhar com versionamento de cÃ³digo no GitHub com boas prÃ¡ticas**
  - [x] Utilizar branches e pull requests para organizar o fluxo de trabalho
  - [x] Escrever mensagens de commit claras e informativas
  - [x] Resolver conflitos de merge com seguranÃ§a

- [ ] **Explorar funcionalidades avanÃ§adas conforme a evoluÃ§Ã£o do projeto**
  - [x] Usar cache com Redis para otimizaÃ§Ã£o de desempenho
  - [ ] Realizar deploy em nuvem (Render, Railway ou VPS)
  - [ ] Testar uso de workers com Celery ou RQ (tarefa opcional)
  - [ ] Expor mÃ©tricas bÃ¡sicas (ex: Prometheus ou logs customizados)

---

## ğŸ—‚ï¸ Estrutura de Pastas

```bash
fasttrackapi-projeto-prisma/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/ 
â”‚       â””â”€â”€ ci.yml   
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # Rotas da API (FastAPI Routers)
â”‚   â”‚   â”œâ”€â”€ v1/                 # VersÃ£o da API
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints/      # Endpoints especÃ­ficos (ex: user.py)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py     # 
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ eventos.py  # 
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ users.py    # 
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ws_router.py            # SÃ³ conecta rotas com handlers
â”‚   â”‚   â”‚   â””â”€â”€ api_router.py   # Agrupa todos os endpoints da v1
â”‚   â”œâ”€â”€ core/                   # ConfiguraÃ§Ãµes globais da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ config.py           # Carrega variÃ¡veis de ambiente com Pydantic
â”‚   â”‚   â”œâ”€â”€ contextvars.py      # 
â”‚   â”‚   â”œâ”€â”€ logging_config.py   # 
â”‚   â”‚   â””â”€â”€ security.py         # ConfiguraÃ§Ãµes relacionadas Ã  seguranÃ§a/autenticaÃ§Ã£o
â”‚   â”œâ”€â”€ middleware/             # 
â”‚   â”‚   â””â”€â”€ logging_middleware.py # 
â”‚   â”œâ”€â”€ models/                 # Modelos do banco de dados (SQLAlchemy)
â”‚   â”œâ”€â”€ repositories/           # FunÃ§Ãµes de acesso ao banco de dados
â”‚   â”‚   â”œâ”€â”€ event_mem.py       # 
â”‚   â”‚   â””â”€â”€ evento.py           # 
â”‚   â”œâ”€â”€ schemas/                # Modelos de entrada/saÃ­da (Pydantic)
â”‚   â”‚   â”œâ”€â”€ event_create.py     # 
â”‚   â”‚   â”œâ”€â”€ event_update.py     # 
â”‚   â”‚   â”œâ”€â”€ local_info.py       # 
â”‚   â”‚   â”œâ”€â”€ token.py            # 
â”‚   â”‚   â”œâ”€â”€ user.py             # 
â”‚   â”‚   â”œâ”€â”€ venue_type.py       # 
â”‚   â”‚   â””â”€â”€ weather_forecast.py # 
â”‚   â”œâ”€â”€ services/               # LÃ³gica de negÃ³cio
â”‚   â”‚   â”œâ”€â”€ interfaces/                 # 
â”‚   â”‚   â”‚   â”œâ”€â”€ forecast_info.py             # 
â”‚   â”‚   â”‚   â”œâ”€â”€ local_info.py       # 
â”‚   â”‚   â”‚   â””â”€â”€ user.py # 
â”‚   â”‚   â”œâ”€â”€ auth_service.py            # 
â”‚   â”‚   â”œâ”€â”€ mock_forecast_info.py             # 
â”‚   â”‚   â”œâ”€â”€ mock_local_info.py       # 
â”‚   â”‚   â””â”€â”€ mock_users.py # 
â”‚   â”œâ”€â”€ utils/                  # FunÃ§Ãµes auxiliares
â”‚   â”‚   â””â”€â”€ cache.py # 
â”‚   â”œâ”€â”€ deps.py                 # DependÃªncias compartilhadas (ex: get_db)
â”‚   â””â”€â”€ main.py                 # Ponto de entrada da aplicaÃ§Ã£o FastAPI
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                   # Testes unitÃ¡rios
â”‚   â”‚   â”œâ”€â”€ __init__.py            # 
â”‚   â”‚   â”œâ”€â”€ conftest.py              # 
â”‚   â”‚   â”œâ”€â”€ test_auth.py       # 
â”‚   â”‚   â”œâ”€â”€ test_eventos.py              # 
â”‚   â”‚   â”œâ”€â”€ test_orecast_info.py       # 
â”‚   â”‚   â””â”€â”€ test_local_info.py # 
â”‚   â”œâ”€â”€ integration/            # Testes de integraÃ§Ã£o (rotas completas)
â”‚   â””â”€â”€ conftest.py             # ConfiguraÃ§Ãµes e fixtures para testes
â”œâ”€â”€ websockets/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ manager.py              # Gerencia conexÃµes
â”‚   â”œâ”€â”€ events.py               # Eventos relacionados a /eventos
â”‚   â””â”€â”€ dashboard.py            # Contador ao vivo e usuÃ¡rios online
â”‚
â”œâ”€â”€ .env                        # VariÃ¡veis de ambiente (nÃ£o versionado) â† padrÃ£o (dev)
â”œâ”€â”€ .env.prod                   # â† produÃ§Ã£o
â”œâ”€â”€ .env.test                   # â† testes/CI
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o com banco de dados e Redis
â”œâ”€â”€ Dockerfile                  # Imagem Docker da aplicaÃ§Ã£o
â”œâ”€â”€ pyproject.toml              # Gerenciado pelo Poetry (dependÃªncias, versÃ£o, etc)
â”œâ”€â”€ poetry.lock                 # Trava das versÃµes instaladas
â”œâ”€â”€ README.md                   # DocumentaÃ§Ã£o principal do projeto
â”œâ”€â”€ ROADMAP.md                  # 
â”œâ”€â”€ TROUBLESHOOTING.md          # 
â””â”€â”€ .gitignore                  # Arquivos ignorados pelo Git
```

---

## ğŸ§ª Finalidade do Projeto

O Projeto Prisma simula uma aplicaÃ§Ã£o real de gerenciamento de eventos, proporcionando a integraÃ§Ã£o com mÃºltiplas fontes de dados e promovendo uma experiÃªncia prÃ¡tica de desenvolvimento backend completo.

### VisÃ£o Geral

A aplicaÃ§Ã£o permite que usuÃ¡rios criem e visualizem eventos. Cada evento pode conter informaÃ§Ãµes como tÃ­tulo, descriÃ§Ã£o, data e local. AlÃ©m disso, a aplicaÃ§Ã£o enriquece os dados do evento com informaÃ§Ãµes obtidas de fontes externas:

1. **Banco de Dados Interno (PostgreSQL):**  
   Armazena todas as informaÃ§Ãµes principais dos eventos, como tÃ­tulo, descriÃ§Ã£o, data, local e participantes.

2. **Banco de Dados Externo Simulado (API controlada):**  
   Representa um sistema externo com dados complementares, como a capacidade de locais ou histÃ³rico de eventos em determinado espaÃ§o. Esse banco serÃ¡ acessado via uma API REST criada especificamente para simular esse comportamento.

3. **API PÃºblica (OpenWeatherMap):**  
   Fornece previsÃµes do tempo baseadas na data e local do evento, integrando dados do mundo real Ã  aplicaÃ§Ã£o.

### Exemplo de Fluxo

- O usuÃ¡rio cria um evento pelo backend.
- A aplicaÃ§Ã£o:
  - Armazena os dados no banco de dados interno.
  - Consulta a API simulada para informaÃ§Ãµes do local.
  - Consulta a API pÃºblica para obter a previsÃ£o do tempo.
- Os dados combinados sÃ£o exibidos ao usuÃ¡rio final.

### BenefÃ­cios TÃ©cnicos

- Simula um ambiente profissional com mÃºltiplas fontes de dados.
- Exerce o consumo de APIs externas com autenticaÃ§Ã£o.
- Trabalha com integraÃ§Ã£o de banco de dados interno e APIs REST externas.
- Promove a aplicaÃ§Ã£o dos conceitos de arquitetura, seguranÃ§a, testes e boas prÃ¡ticas.

---

## DivisÃ£o dos ambientes

# 3.1 â€” DEV  (Ã© o default â€“ pode atÃ© omitir)
uvicorn app.main:app --reload
# ou
ENV=dev uvicorn app.main:app --reload


# 3.2 â€” TESTE  (Ãºtil p/ CI/local)
ENV=test pytest -q                       # carrega .env.test
# ou, se quiser subir a API no modo test:
ENV=test uvicorn app.main:app


# 3.3 â€” PRODUÃ‡ÃƒO  (simulaÃ§Ã£o local)
ENV=prod uvicorn app.main:app --host 0.0.0.0 --port 8000

---

## ğŸ§­ PrÃ³ximo Passo do Desenvolvimento

O prÃ³ximo passo serÃ¡ **escolher uma das trÃªs frentes iniciais para iniciar o desenvolvimento prÃ¡tico**:

1. **Criar a primeira rota da API (ex: rota de usuÃ¡rios ou status)**  
2. **Configurar o banco de dados e a primeira modelagem com SQLAlchemy + Alembic**  
3. **Implementar os primeiros testes automatizados com Pytest**

> RecomendaÃ§Ã£o: comeÃ§ar pela criaÃ§Ã£o da primeira rota para jÃ¡ ver a API funcionando e integrar gradualmente os demais pontos.

---

## ğŸ§± Estrutura Conceitual dos Dados

### 1. Banco de Dados Interno (PostgreSQL)
ResponsÃ¡vel por armazenar todos os dados principais dos eventos criados pelos usuÃ¡rios.

#### ğŸ“Œ InformaÃ§Ãµes Armazenadas no Evento:

| Campo          | Tipo        | DescriÃ§Ã£o                                                     |
|----------------|-------------|----------------------------------------------------------------|
| `id`           | int         | Identificador Ãºnico do evento                                 |
| `title`        | str         | TÃ­tulo do evento                                              |
| `description`  | str         | DescriÃ§Ã£o detalhada                                           |
| `event_date`   | datetime    | Data e hora do evento                                         |
| `location_name`| str         | Nome do local (referÃªncia cruzada com API externa)            |
| `created_at`   | datetime    | Data de criaÃ§Ã£o do evento                                     |
| `updated_at`   | datetime    | Ãšltima modificaÃ§Ã£o                                            |
| `participants` | List[str]   | Lista de nomes dos participantes                              |
| `local_info`   | dict        | Dados retornados da API do banco externo (opcional)           |
| `forecast_info`| dict        | Dados retornados da API pÃºblica (opcional)                   |

---

### 2. Banco de Dados Externo Simulado (via API prÃ³pria)
Esse "banco externo" serÃ¡ acessado via uma API REST e irÃ¡ fornecer informaÃ§Ãµes complementares sobre o local do evento.

#### ğŸ“¡ Dados esperados da API externa:

| Campo          | Tipo        | DescriÃ§Ã£o                                                  |
|----------------|-------------|-------------------------------------------------------------|
| `location_name`| str         | Nome do local (chave de busca)                             |
| `capacity`     | int         | Capacidade mÃ¡xima de pessoas                               |
| `venue_type`   | str         | Tipo de local (ex: auditÃ³rio, salÃ£o, espaÃ§o aberto)        |
| `is_accessible`| bool        | Se possui acessibilidade                                   |
| `address`      | str         | EndereÃ§o completo                                          |
| `past_events`  | List[str]   | Lista de eventos anteriores jÃ¡ realizados nesse local      |

---

### 3. API PÃºblica (OpenWeatherMap)
ServirÃ¡ para buscar previsÃµes meteorolÃ³gicas para a data e local do evento.

#### ğŸŒ¤ï¸ Dados coletados:

| Campo             | Tipo     | DescriÃ§Ã£o                                 |
|------------------|----------|--------------------------------------------|
| `forecast_datetime` | datetime | Data e hora da previsÃ£o                  |
| `temperature`     | float    | Temperatura prevista (em Â°C)              |
| `weather_main`    | str      | DescriÃ§Ã£o curta (ex: Rain, Clear)         |
| `weather_desc`    | str      | DescriÃ§Ã£o completa (ex: light rain)       |
| `humidity`        | int      | Umidade relativa (%)                      |
| `wind_speed`      | float    | Velocidade do vento (m/s)                 |

### Sobre o uso de `Optional`
Em Python, `Optional[T]` significa que o campo pode ser do tipo `T` ou `None`.  
No Pydantic, isso permite que os campos sejam omitidos na entrada. Isso Ã© Ãºtil para situaÃ§Ãµes em que nem todos os dados estÃ£o disponÃ­veis imediatamente, como Ã© o caso de integraÃ§Ãµes com APIs externas que podem falhar ou demorar para responder.

---

## ğŸ“¦ Tipos e ValidaÃ§Ãµes

Durante o desenvolvimento, os dados tratados incluem tipos comuns como texto (strings), nÃºmeros inteiros, valores decimais, datas e listas. Em alguns momentos, sÃ£o utilizados tipos de dados estruturados mais flexÃ­veis, como o tipo `dict`.

O tipo `dict` representa um conjunto de pares de chave e valor. Ele Ã© Ãºtil quando o conteÃºdo pode variar ou nÃ£o Ã© conhecido com antecedÃªncia. Apesar disso, sempre que a estrutura de um dado for previsÃ­vel, ela serÃ¡ modelada de forma explÃ­cita para garantir seguranÃ§a e clareza no cÃ³digo.

Todos os dados manipulados nas entradas e saÃ­das da aplicaÃ§Ã£o serÃ£o validados por modelos `Pydantic`. O Pydantic permite criar classes que representam a estrutura esperada dos dados, garantindo que eles estejam no formato correto antes de serem usados ou armazenados. Ele tambÃ©m realiza conversÃµes automÃ¡ticas de tipo, fornece mensagens de erro claras em caso de dados invÃ¡lidos e integra perfeitamente com o FastAPI para geraÃ§Ã£o automÃ¡tica de documentaÃ§Ã£o.

A utilizaÃ§Ã£o do Pydantic torna o projeto mais robusto, seguro e fÃ¡cil de manter.

---

## ğŸ§© Schemas do Projeto

Os schemas representam os modelos de dados utilizados para entrada e saÃ­da de informaÃ§Ãµes na API. Eles sÃ£o criados com `Pydantic` e aproveitam o uso de `Annotated` para adicionar metadados como validaÃ§Ãµes, descriÃ§Ãµes e regras de negÃ³cio.

### Modelos Criados:

- **EventCreate**: utilizado ao criar um novo evento. Permite inserir os dados principais, e os campos `local_info` e `forecast_info` sÃ£o opcionais.
- **EventUpdate**: utilizado para atualizar os dados de um evento apÃ³s a criaÃ§Ã£o. Exige os campos `local_info` e `forecast_info`, que contÃªm dados externos.
- **LocalInfo**: estrutura esperada da API simulada com dados sobre o local do evento, como capacidade, tipo, acessibilidade e endereÃ§o.
- **WeatherForecast**: estrutura que representa os dados retornados pela API pÃºblica de previsÃ£o do tempo.

Todos esses modelos estÃ£o localizados na pasta `app/schemas/` e sÃ£o essenciais para garantir a validaÃ§Ã£o de dados, a integridade da aplicaÃ§Ã£o e a geraÃ§Ã£o automÃ¡tica da documentaÃ§Ã£o da API via OpenAPI/Swagger.

---

## ğŸ”§ ModificaÃ§Ãµes recentes

- MigraÃ§Ã£o da estrutura de armazenamento de lista para `dict` (`eventos_db`)
- Uso de tipos explÃ­citos de retorno nas funÃ§Ãµes de endpoint
- `location_name` removido da entrada direta do usuÃ¡rio (`EventCreate`)
- `LocalInfo` Ã© gerado com base em API externa; se nÃ£o houver retorno, salva-se apenas `location_name`

---

## ğŸ¤ª Como executar localmente

### PrÃ©-requisitos
- Python 3.12+
- [Poetry](https://python-poetry.org/docs/)

### InstalaÃ§Ã£o e execuÃ§Ã£o

```bash
# Clone o repositÃ³rio
https://github.com/seu-usuario/FastTrackAPI---Projeto-Prisma.git
cd FastTrackAPI---Projeto-Prisma

# Instale as dependÃªncias
poetry install

# (opcional) Ative o shell do poetry
poetry self add poetry-plugin-shell  # somente na primeira vez
poetry shell

# Execute a aplicaÃ§Ã£o
uvicorn app.main:app --reload
```

projetos FastAPI.

âœ… Passo a passo para testar localmente
1. ğŸ“¦ Ative o ambiente virtual (ou use o poetry se estiver configurado)
Se estiver usando venv:

poetry install

Habilitar o plugin de shell antigo
Se vocÃª quiser voltar a usar o poetry shell, rode isso uma Ãºnica vez:

poetry self add poetry-plugin-shell

Depois vocÃª poderÃ¡ usar normalmente:

poetry shell

2. ğŸ“¥ Instale o FastAPI e o Uvicorn (se ainda nÃ£o tiver)


pip install fastapi uvicorn

3. â–¶ï¸ Execute o servidor
A partir da pasta raiz do projeto (onde estÃ¡ o diretÃ³rio app/), rode:

uvicorn app.main:app --reload

Isso diz: â€œinicie a aplicaÃ§Ã£o FastAPI localizada em app/main.py, dentro do objeto appâ€

4. ğŸŒ Acesse a documentaÃ§Ã£o da API

ApÃ³s rodar o comando, acesse:

http://localhost:8000/docs â†’ Swagger UI (interativo)

http://localhost:8000/redoc â†’ ReDoc (documentaÃ§Ã£o formal)

VocÃª pode instalar a lib diretamente com o Poetry   como uma dependÃªncia de desenvolvimento (ideal para testes). Ex com o httpx

poetry add --dev httpx

### Acesse a API
- Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)
- Redoc: [http://localhost:8000/redoc](http://localhost:8000/redoc)

### Testes

```bash
# Execute todos os testes com cobertura
pytest --cov=app --cov-report=term-missing
poetry run pytest --cov=app --cov-report=xml --cov-report=html
```

Para garantir que tudo funcione corretamente, instale as dependÃªncias de teste:

```bash
poetry add --dev pytest pytest-cov httpx
```

### Sobre o pyproject.toml

- As dependÃªncias principais ficam na seÃ§Ã£o `[tool.poetry.dependencies]`
- As dependÃªncias de desenvolvimento (testes, lint, etc.) vÃ£o em `[tool.poetry.group.dev.dependencies]`

Exemplo:
```toml
[tool.poetry.dependencies]
fastapi = "^0.110.0"
uvicorn = "^0.29.0"

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
pytest-cov = "^4.1.0"
httpx = "^0.27.0"
```

---

### CI com GitHub Actions

O projeto pode utilizar GitHub Actions para rodar testes automaticamente a cada push ou pull request.

Crie um arquivo `.github/workflows/tests.yml` com o conteÃºdo:

```yaml
name: Testes e Cobertura

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout do repositÃ³rio
        uses: actions/checkout@v3

      - name: Instalar Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.12

      - name: Instalar Poetry
        run: |
          pip install poetry
          poetry install

      - name: Rodar testes com cobertura
        run: |
          poetry run pytest --cov=app --cov-report=xml --cov-report=term

      - name: Enviar para Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          fail_ci_if_error: true
```

Certifique-se de criar uma conta no [https://codecov.io](https://codecov.io) e conectar com seu repositÃ³rio GitHub para ativar o badge corretamente.

Rodar testes localmente igual ao CI
# 1Âª vez
  poetry install --with dev --no-interaction
# sempre que for commitar
  poetry run pytest --cov=app --cov-report=term-missing

Adicione a dependÃªncia no grupo dev para rodar localmente:
  poetry add --group dev ruff

# pyproject.toml
[tool.ruff]
line-length = 100               # segue no nÃ­vel raiz (formataÃ§Ã£o)

[tool.ruff.lint]                # â¬…ï¸ tudo abaixo diz respeito ao *linter*
select = ["E", "F", "I", "UP", "D"]   # incluÃ­ "D" para docstrings
ignore = ["F401"]                     # exemplo: allow unused import
extend-ignore = ["D203", "D213"]      # (explico no ponto 2)
preview = true                        # jÃ¡ usa as regras â€œnext-genâ€

# Regras diferentes para testes
[tool.ruff.per-file-ignores]
"tests/**/*" = ["D", "E501"]         # sem docstring + sem limite de linha

# Exemplo de exclusÃ£o de diretÃ³rio
[tool.ruff.exclude]
extend = ["migrations", "scripts"]

2 âš ï¸ Conflito D203 Ã— D211 e D212 Ã— D213
Esses sÃ£o regras de docstring da famÃ­lia pydocstyle:

CÃ³digo	Regra resumida	IncompatÃ­vel com
D203	â€œPrecisa de uma linha em branco antes de cada class docstringâ€	D211
D211	â€œNÃ£o pode haver linha em branco antes da docstringâ€	D203
D212	Para docstring multilinha, o resumo deve iniciar na primeira linha	D213
D213	Para docstring multilinha, o resumo deve iniciar na segunda linha	D212

Rode Ruff + Pytest com os mesmos flags:
  poetry run ruff check .
  pyupgrade --py312-plus --exit-zero-even-if-changed $(git ls-files '*.py')
  poetry run mypy app
  poetry run bandit -q -r app -lll
  poetry run pytest -x --cov=app --cov-report=xml --cov-report=html --cov-fail-under=80
    poetry run pytest tests/unit/test_localinfo.py --cov=app --cov-fail-under=80
    poetry run pytest --cov=app --cov-report=xml --cov-report=html --cov-fail-under=80

Seguindo esses passos, vocÃª terÃ¡ um pipeline que:
  Corrige estilo e ordena imports (Ruff)
  Alerta para sintaxe obsoleta (PyUpgrade)
  Garante tipagem correta (MyPy)
  Aponta falhas de seguranÃ§a (Bandit)
  Executa testes com cobertura mÃ­nima definida

Se vocÃª quiser simular o workflow localmente, use o act (opcional):
  brew install act            # ou choco install act no Windows
  act push --job test

AnotaÃ§Ãµes no PR: quando um action devolve logs no formato GitHub Diagnostic Format, o GitHub cria inline comments na aba Files changed.
  ruff check --output-format=github

Erros â€œfixÃ¡veisâ€ (marcados com [*]):
  poetry run ruff check --fix .

Erros nÃ£o auto-corrigÃ­veis:

F821 timezoneâ€ƒâ†’â€ƒfaltou importar ou definir timezone.

F811 redefinitionâ€ƒâ†’â€ƒtem duas funÃ§Ãµes/fixtures com o mesmo nome; renomeie ou remova duplicata.

F601 key 201 repeatedâ€ƒâ†’â€ƒvocÃª tem {201: ..., 201: ...} na mesma dict.

Undefined name EventCreate nos testesâ€ƒâ†’â€ƒadicione from app.schemas.event_create import EventCreate.

.

1ï¸âƒ£ MyPy â€“ verificador de type hints
  âœ¨ O que Ã©
  Analisa os type hints do Python (def foo(x: int) -> str:) e compara com o fluxo real do cÃ³digo.

  Encontra incongruÃªncias de tipos antes de vocÃª rodar o programa.

  âš™ï¸ Como adicionar
    poetry add --group dev mypy

.

2ï¸âƒ£ Bandit â€“ linter de seguranÃ§a
  âœ¨ O que Ã©
  Avalia source Python em busca de â€œCommon Weaknessesâ€ (CWE):
  â€£ uso de eval, â€£ chaves criptogrÃ¡ficas hard-coded, â€£ subprocess sem shell=False, â€£ hashlib.md5, etc.

  âš™ï¸ Como adicionar
    poetry add --group dev bandit

.

3ï¸âƒ£ PyUpgrade â€“ modernizador de sintaxe
  âœ¨ O que Ã©
  Reescreve automaticamente trechos antigos para a versÃ£o Python que vocÃª escolher. Exemplos:

  list(x for x in y) â†’ [x for x in y]

  from typing import List + List[int] â†’ list[int] (Py 3.9+)

  Remove six, converte super(Class, self) â†’ super()

  âš™ï¸ Como adicionar
    poetry add --group dev pyupgrade
  Uso local
    pyupgrade --py312-plus $(git ls-files '*.py')

CodeQL e DependaBoot onhold por enquanto
4ï¸âƒ£ CodeQL â€“ anÃ¡lise de vulnerabilidade mantida pelo GitHub
âœ¨ O que Ã©
Compila seu projeto para um grafo semÃ¢ntico e executa consultas (â€œqueriesâ€) que detectam padrÃµes inseguros, SQL-Injection, Path-Traversal etc.
Ã‰ a soluÃ§Ã£o oficial de Code Scanning do GitHub Advanced Security (grÃ¡tis em repositÃ³rios pÃºblicos).

5ï¸âƒ£ Dependabot (Security Spotlight)
âœ¨ O que Ã©
ServiÃ§o do GitHub que cria Pull Requests automÃ¡ticos quando sai versÃ£o nova (ou patch de seguranÃ§a) de dependÃªncias.


---

## Links de ReferÃªncia

https://open-meteo.com/en/docs
https://open-meteo.com/en/docs?latitude=-8.0539&longitude=-34.8811
https://publicapis.dev/
https://www.mongodb.com/try/download/odbc-driver


Pendente organizaÃ§Ã£o

FastTrackAPI â€“ Projeto Prisma ğŸš€

Projeto-laboratÃ³rio de mentoria em backend Python/FastAPI. Aqui testamos, na prÃ¡tica, arquitetura limpa, seguranÃ§a, DevOps, testes e observabilidade â€” tudo versionado no GitHub.

ğŸ“š SumÃ¡rio

VisÃ£o Geral

Objetivos

Estrutura de Pastas

ConfiguraÃ§Ã£o por Ambiente + Fallback Seguro

DependÃªncias ReutilizÃ¡veis e TestÃ¡veis

Filtros & PaginaÃ§Ã£o in-memory

Cache com Redis

Pipeline CI (GitHub Actions)

Roadmap de EvoluÃ§Ã£o

Como Executar Localmente

VisÃ£o Geral

O FastTrackAPI simula um sistema que gerencia eventos. Ele reÃºne diferentes tecnologias como banco de dados (PostgreSQL), APIs externas para previsÃ£o do tempo e informaÃ§Ãµes locais, oferecendo uma experiÃªncia prÃ¡tica completa em backend Python com FastAPI.

Objetivos

Geral

Capacitar no desenvolvimento backend usando Python e FastAPI, com prÃ¡ticas modernas em seguranÃ§a, testes automatizados e DevOps.

EspecÃ­ficos

Implementar uma arquitetura em camadas com boas prÃ¡ticas (SOLID, DRY, KISS).

Usar testes automatizados para garantir a qualidade.

Realizar integraÃ§Ã£o contÃ­nua e deploy contÃ­nuo (CI/CD).

Utilizar cache para otimizar desempenho.

Estrutura de Pastas

fasttrackapi-projeto-prisma/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/endpoints/   # Rotas (URLs) da aplicaÃ§Ã£o.
â”‚   â”œâ”€â”€ core/               # ConfiguraÃ§Ãµes centrais (ambientes, seguranÃ§a).
â”‚   â”œâ”€â”€ repositories/       # Interfaces e implementaÃ§Ãµes para acessar os dados.
â”‚   â”œâ”€â”€ services/           # Regras de negÃ³cio e mocks para testes.
â”‚   â”œâ”€â”€ schemas/            # Modelos dos dados usados na aplicaÃ§Ã£o.
â”‚   â”œâ”€â”€ utils/              # FunÃ§Ãµes Ãºteis e ferramentas (cache, etc.).
â”‚   â””â”€â”€ deps.py             # Gerencia dependÃªncias da aplicaÃ§Ã£o.
â”œâ”€â”€ tests/                  # Testes automatizados.
â”œâ”€â”€ Dockerfile              # Arquivo para criaÃ§Ã£o de container Docker.
â”œâ”€â”€ docker-compose.yml      # Gerenciamento de mÃºltiplos containers.
â”œâ”€â”€ .env                    # VariÃ¡veis de ambiente.
â””â”€â”€ .github/workflows/ci.yml # ConfiguraÃ§Ã£o do pipeline de integraÃ§Ã£o contÃ­nua.

ConfiguraÃ§Ã£o por Ambiente + Fallback Seguro

O sistema suporta trÃªs ambientes: desenvolvimento (dev), testes (test) e produÃ§Ã£o (prod). Cada um possui seu prÃ³prio arquivo .env, que Ã© carregado automaticamente pelo sistema. Caso faltem variÃ¡veis obrigatÃ³rias em produÃ§Ã£o, o sistema gera um alerta, garantindo seguranÃ§a e estabilidade.

DependÃªncias ReutilizÃ¡veis e TestÃ¡veis

As dependÃªncias sÃ£o organizadas em protocolos (contratos) definidos claramente. Isso permite facilmente substituir implementaÃ§Ãµes reais por versÃµes simplificadas (mocks) durante os testes, garantindo testes rÃ¡pidos, claros e independentes.

Filtros & PaginaÃ§Ã£o in-memory

Antes de conectar o banco de dados definitivo, usamos um mÃ©todo interno para realizar filtros e paginaÃ§Ã£o diretamente na memÃ³ria do sistema. Isso permite que as APIs sejam testadas rapidamente sem depender do banco externo.

Cache com Redis

Usamos o Redis para armazenar temporariamente resultados de operaÃ§Ãµes comuns e demoradas, reduzindo a carga no sistema e melhorando a performance geral da aplicaÃ§Ã£o. Exemplos sÃ£o resultados de previsÃµes climÃ¡ticas e informaÃ§Ãµes locais que raramente mudam.

Pipeline CI (GitHub Actions)

A integraÃ§Ã£o contÃ­nua (CI) Ã© configurada atravÃ©s do GitHub Actions, que realiza automaticamente os seguintes passos ao atualizar o cÃ³digo:

Executa testes em diferentes versÃµes do Python (3.10, 3.11, 3.12) em mÃºltiplas plataformas (Ubuntu e Windows).

Analisa o cÃ³digo buscando erros de estilo e seguranÃ§a.

Verifica cobertura de testes.

Publica relatÃ³rios de testes e cobertura automaticamente.

Roadmap de EvoluÃ§Ã£o

Planejamento futuro detalhado:

ImplementaÃ§Ã£o de logs estruturados.

AutomatizaÃ§Ã£o de tarefas em segundo plano.

Melhorias de seguranÃ§a (controle de acessos, proteÃ§Ã£o contra ataques).

ImplantaÃ§Ã£o da aplicaÃ§Ã£o em ambiente de produÃ§Ã£o real usando containerizaÃ§Ã£o.

Como Executar Localmente

Passo a passo simples

Clone o projeto:

git clone https://github.com/SEU_USUARIO/FastTrackAPI---Projeto-Prisma.git
cd FastTrackAPI---Projeto-Prisma

Instale as dependÃªncias:

poetry install

Inicie o servidor local em ambiente de desenvolvimento:

uvicorn app.main:app --reload

Acesse a documentaÃ§Ã£o interativa:

http://localhost:8000/docs

ExecuÃ§Ã£o de testes:

ENV=test pytest -q

Com estas instruÃ§Ãµes detalhadas, vocÃª jÃ¡ pode comeÃ§ar a trabalhar no FastTrackAPI â€“ Projeto Prisma, praticando desenvolvimento backend com qualidade profissional!

# FastTrackAPI â€“ Projeto Prisma

[![Coverage](https://codecov.io/gh/SEU_USUARIO/FastTrackAPI---Projeto-Prisma/branch/main/graph/badge.svg)](https://codecov.io/gh/SEU_USUARIO/FastTrackAPI---Projeto-Prisma)

---

## âœ… AtualizaÃ§Ã£o: DependÃªncias ReutilizÃ¡veis e TestÃ¡veis

Este projeto adota o padrÃ£o de **injeÃ§Ã£o de dependÃªncia com contratos (Protocol)** para tornar o cÃ³digo mais **modular**, **testÃ¡vel** e **substituÃ­vel** sem alterar os endpoints principais.

### ğŸ“Œ O que foi feito:

1. **Definimos contratos (`Protocol`)** para todos os serviÃ§os: usuÃ¡rios, eventos, previsÃ£o do tempo e local.
2. **Criamos implementaÃ§Ãµes mockÃ¡veis** com dados estÃ¡ticos para testes e desenvolvimento.
3. **Registramos providers Ãºnicos** no arquivo `deps.py`, permitindo troca fÃ¡cil entre mocks e implementaÃ§Ãµes reais.
4. **Atualizamos todos os endpoints** para receberem dependÃªncias via `Depends(...)`, sem acoplamento a implementaÃ§Ãµes concretas.

### ğŸ” BenefÃ­cios desta abordagem

* **Testes unitÃ¡rios e de integraÃ§Ã£o facilitados:** cada serviÃ§o pode ser substituÃ­do por um fake/mocker no momento do teste, sem alterar a lÃ³gica das rotas.
* **Menor acoplamento:** a lÃ³gica da aplicaÃ§Ã£o depende apenas de contratos, nÃ£o de implementaÃ§Ãµes especÃ­ficas.
* **Flexibilidade futura:** mudar de banco de dados ou de API de clima exige apenas trocar a implementaÃ§Ã£o do contrato, mantendo as rotas intactas.
* **Alinhado ao SOLID (Dependency Inversion Principle):** alta coesÃ£o, baixo acoplamento e extensibilidade segura.

### ğŸ§ª O que pode ser testado com essa estrutura

Com o uso de dependÃªncias injetÃ¡veis, Ã© possÃ­vel testar isoladamente:

* AutenticaÃ§Ã£o de usuÃ¡rios (via `MockUserRepo`)
* Consultas e atualizaÃ§Ãµes de eventos (via `InMemoryEventoRepo`)
* Enriquecimento de eventos com previsÃ£o do tempo (`MockForecastService`)
* Enriquecimento de eventos com dados de local (`MockLocalInfoService`)
* Respostas esperadas para permissÃµes e acessos (admin, editor, viewer)

### ğŸ§© Exemplo de contrato criado:

```python
# app/repositories/evento.py
from typing import Protocol
from app.schemas.event_create import EventCreate, EventResponse

class AbstractEventRepo(Protocol):
    def list_all(self) -> list[EventResponse]: ...
    def get(self, evento_id: int) -> EventResponse | None: ...
    def add(self, evento: EventCreate) -> EventResponse: ...
    def replace_all(self, eventos: list[EventResponse]) -> list[EventResponse]: ...
    def replace_by_id(self, evento_id: int, evento: EventResponse) -> EventResponse: ...
    def delete_all(self) -> None: ...
    def delete_by_id(self, evento_id: int) -> bool: ...
    def update(self, evento_id: int, data: dict) -> EventResponse: ...
```

---

> ğŸ’¡ Todos os serviÃ§os que dependem de `users`, `forecast`, `local_info` e `eventos` jÃ¡ foram refatorados. Veja exemplos no diretÃ³rio `app/services/`, `app/repositories/` e `app/deps.py`.

# FastTrackAPI â€“ Projeto Prisma

[![Coverage](https://codecov.io/gh/SEU_USUARIO/FastTrackAPI---Projeto-Prisma/branch/main/graph/badge.svg)](https://codecov.io/gh/SEU_USUARIO/FastTrackAPI---Projeto-Prisma)

Este repositÃ³rio faz parte de uma mentoria prÃ¡tica de backend com Python e FastAPI.

---

## ğŸ” ConfiguraÃ§Ã£o por Ambiente + Fallback Seguro

Gerenciamos **trÃªs ambientes padrÃ£o** â€” `dev`, `test` e `prod` â€” cada qual com seu prÃ³prio arquivo de variÃ¡veis:

| Arquivo     | Quando Ã© lido                   | Exemplo de conteÃºdo                                             |
| ----------- | ------------------------------- | --------------------------------------------------------------- |
| `.env`      | Desenvolvimento local (default) | `ENVIRONMENT=dev`  Â  `DB_URL=postgres://localhost/dev_db`       |
| `.env.test` | ExecuÃ§Ã£o da suÃ­te *pytest*/CI   | `ENVIRONMENT=test`  Â  `DB_URL=postgres://localhost/test_db`     |
| `.env.prod` | Deploy em produÃ§Ã£o              | `ENVIRONMENT=prod`  Â  `DB_URL=postgres://postgres:5432/prod_db` |

> **Importante:** nunca commitamos segredos reais em `.env.prod`. Em produÃ§Ã£o as chaves vÃªm de *secretâ€‘manager* ou de variÃ¡veis do host.

### Onde estÃ¡ implementado

* `app/core/config.py` â€“ classe **`Settings`** (Pydantic v2) lÃª todas as variÃ¡veis:

  * `environment`, `db_url`, `redis_url`, `auth_secret_key`, etc.
  * `model_config` define `env_file=(".env", ".env.prod", ".env.test")`, `extra="forbid"` e `case_sensitive=False`.
  * ValidaÃ§Ã£o extra `@field_validator("redis_url")` obriga Redis em `prod`.
  * FunÃ§Ã£o `get_settings()` com `@lru_cache` garante leitura uma Ãºnica vez.

Estrutura resumida (trecho):

```python
class Settings(BaseSettings):
    environment: str = Field("dev", alias="ENVIRONMENT")  # fallback â†’ dev
    db_url: str = Field(..., alias="DB_URL")
    redis_url: str | None = Field(None, alias="REDIS_URL")
    auth_secret_key: str = Field(..., alias="AUTH_SECRET_KEY")

    model_config = SettingsConfigDict(
        env_file=(".env", ".env.prod", ".env.test"),
        extra="forbid",
    )

    @field_validator("redis_url", mode="after")
    def require_redis_in_prod(cls, v, info):
        if info.data.get("environment") == "prod" and not v:
            raise ValueError("REDIS_URL Ã© obrigatÃ³rio em produÃ§Ã£o")
        return v
```

### Como trocar de ambiente sem Docker

```bash
# Desenvolvimento (default)
uvicorn app.main:app --reload

# Testes/CI
ENV=test pytest -q           # usa .env.test

# Simular produÃ§Ã£o local
ENV=prod uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### Possibilidades habilitadas pela abordagem

* **Isolamento total** de bases de dados/serviÃ§os entre `dev`, `test` e `prod`.
* **Failâ€‘fast**: variÃ¡veis desconhecidas ou obrigatÃ³rias ausentes derrubam a app no start.
* **Feature flags** por ambiente (ex.: ativar um provider ou log extra sÃ³ em `dev`).
* **Secrets seguros** em produÃ§Ã£o, lidos do ambiente/container, nunca versionados.
* **Deploy simples**: `ENV=prod docker compose up -d` carrega `.env` + `.env.prod`.

---

âœï¸ Proposta de adiÃ§Ã£o ao README.md
markdown
Copiar
## Filtros e PaginaÃ§Ã£o *in-memory*

> **Por que existe:** antes de ligar um banco SQL/NoSQL queremos que a API jÃ¡ exponha paginaÃ§Ã£o (`skip` / `limit`) e filtros de consulta (ex.: `city=Recife`). Assim o front-end e os testes de integraÃ§Ã£o continuam exatamente iguais quando trocarmos a camada de persistÃªncia â€” princÃ­pio **OCP / port-adapter**.

### Como funciona

1. **RepositÃ³rio em memÃ³ria**  
   `app/repositories/event_mem.py` ganhou o mÃ©todo  
   ```python
   def list_partial(self, *, skip: int = 0, limit: int = 20, **filters)
ConstrÃ³i uma lista a partir do dicionÃ¡rio interno

Aplica cada filtro recebido (city, date_from, etc.)

Devolve apenas a fatia data[skip: skip+limit]

Contrato da interface
A AbstractEventRepo ( app/repositories/evento.py ) agora declara list_partial, garantindo que qualquer implementaÃ§Ã£o futura (SQLAlchemy, Elastic, Redisâ€¦) respeite a mesma assinatura.

Rotas

GET /api/v1/eventos
Recebe skip, limit, city como query params e simplesmente delega para repo.list_partial(...)

A rota legada /eventos/todos foi removida: listar tudo sem filtro/paginaÃ§Ã£o nÃ£o Ã© mais suportado.

Testes

tests/unit/test_eventos.py atualizados para fabricar eventos via Pydantic (EventCreate) e cobrir cenÃ¡rios de paginaÃ§Ã£o e filtros.

Cobertura total da suÃ­te volta a ficar â‰¥ 80 %.

BenefÃ­cios imediatos
âœ”ï¸ BenefÃ­cio	ğŸš€ Impacto
Mesmo contrato HTTP hoje e depois do banco	zero retrabalho no front-end
Feedback rÃ¡pido no CI â€“ tudo roda sÃ³ em RAM	build & testes â‰¤ 5 s
Facilita benchmark de slice vs cursor	decide-se depois se precisa de paginaÃ§Ã£o baseada em cursor ou token
Permite cachÃª fÃ¡cil na etapa seguinte	a lista paginada jÃ¡ Ã© determinÃ­stica â†’ @cache

PrÃ³ximos passos possÃ­veis
Trocar storage: basta criar EventoSQLRepo que implemente list_partial com select(...).where(...).offset(skip).limit(limit).

Novos filtros: adicione parÃ¢metros opcionais na rota e passe-os ao repo; a assinatura pÃºblica permanece idÃªntica.

Cursor Pagination: manter skip/limit para retro-compatibilidade e aceitar um cursor para coleÃ§Ãµes muito grandes.

ğŸ’¡ Onde olhar no cÃ³digo

Arquivo	O que mudou
app/repositories/evento.py	nova list_partial na interface
app/repositories/event_mem.py	implementaÃ§Ã£o da funÃ§Ã£o + refactor interno
app/api/v1/endpoints/eventos.py	rota /eventos usa list_partial; rota /eventos/todos removida
tests/unit/test_eventos.py	usa modelos Pydantic e cobre paginaÃ§Ã£o/filtros

Copie o bloco acima para o seu README.md (ou crave um link direto para este ponto do documento se jÃ¡ existir uma seÃ§Ã£o â€œArquiteturaâ€). Qualquer ajuste de nomenclatura/caminho Ã© sÃ³ trocar aqui e dar git commit -m "docs(readme): explica filtros e paginaÃ§Ã£o in-memory".






ğŸ”„ AtualizaÃ§Ã£o sugerida para o README.md
markdown
Copiar
Editar
## Filtros e PaginaÃ§Ã£o *in-memory*

> **MotivaÃ§Ã£o:** antes de plugarmos PostgreSQL/SQLAlchemy, jÃ¡ queremos que a API exponha paginaÃ§Ã£o (`skip` + `limit`) e filtros arbitrÃ¡rios via *query params*. Assim o front-end, os testes e a documentaÃ§Ã£o Swagger permanecem **iguais** quando trocarmos apenas a camada de persistÃªncia â€” princÃ­pio Open-Closed (OCP).

---

### VisÃ£o de alto nÃ­vel  

1. **RepositÃ³rio em memÃ³ria**  
   `app/repositories/event_mem.py` implementa  
   ```python
   def list_partial(self, *, skip: int = 0, limit: int = 20, **filters)
Converte o dicionÃ¡rio interno em lista.

Aplica dinamicamente cada par chave=valor recebido (ex.: city="Recife").

Retorna somente a fatia data[skip : skip + limit].

ğŸ“ Por que **filters?

Evita â€œquebrarâ€ o contrato pÃºblico quando surgirem filtros novos (ex.: date_from, venue_type).

As implementaÃ§Ãµes futuras (SQL ou Elastic) continuam obedecendo Ã  mesma assinatura, trocando apenas o corpo da funÃ§Ã£o.

Contrato da interface
app/repositories/evento.py declara o mesmo mÃ©todo genÃ©rico:

python
Copiar
Editar
def list_partial(self, *, skip: int = 0, limit: int = 20, **filters) -> list[EventResponse]: ...
Rotas

GET /api/v1/eventos

python
Copiar
Editar
eventos = repo.list_partial(skip=skip, limit=limit, city=city)
â€” qualquer filtro Ã© simplesmente encaminhado como keyword arg.

GET /api/v1/eventos/todos
Mantida apenas para retro-compatibilidade:

python
Copiar
Editar
@router.get("/eventos/todos", deprecated=True, include_in_schema=False)
Ela chama repo.list_all() e logo serÃ¡ removida.

Testes

tests/unit/test_eventos.py fabrica objetos via Pydantic (EventCreate) e cobre cenÃ¡rios de paginaÃ§Ã£o e filtros.

Cobertura total â‰¥ 80 %.

Onde estÃ¡ cada parte
Arquivo	ConteÃºdo relevante
app/repositories/evento.py	interface AbstractEventRepo com list_partial(**filters)
app/repositories/event_mem.py	primeiro adapter concreto: filtra e pagina em RAM
app/api/v1/endpoints/eventos.py	rota /eventos usa o repo; rota /eventos/todos marcada deprecated=True
tests/unit/test_eventos.py	cenÃ¡rios de paginaÃ§Ã£o e filtros com objetos Pydantic

BenefÃ­cios imediatos
âœ”ï¸	Impacto
Contrato estÃ¡vel com **filters	adicionar novos filtros nÃ£o muda assinatura nem quebra clientes
Feedback ultra-rÃ¡pido	CI roda tudo em memÃ³ria; sem container de banco
MigraÃ§Ã£o suave	trocar por session.exec(stmt.where(...).offset(skip).limit(limit)) e pronto
Base p/ cache ou cursor pagination	slice determinÃ­stico facilita evoluÃ§Ãµes de performance

PrÃ³ximos passos
Adicionar filtros extras: basta incluir o parÃ¢metro na rota e encaminhar para list_partial.

Trocar storage: crie SQLEventoRepo que obedece Ã  mesma assinatura.

Cursor-based pagination: manter skip/limit para retro-compatibilidade e aceitar cursor opcional.

sql
Copiar
Editar

Copie o bloco acima para o `README.md` (em â€œArquiteturaâ€ ou â€œFeaturesâ€) e faÃ§a o commit:

```bash
git add README.md
git commit -m "docs(readme): descreve filtros e paginaÃ§Ã£o in-memory com **filters"
Assim o repositÃ³rio continua documentado em sintonia com a implementaÃ§Ã£o real.



**filters percorrido dinamicamente	EscalÃ¡vel: novos filtros (ex. date_from) nÃ£o exigem refactor de assinatura nem de testes.
ComparaÃ§Ã£o â€œcase-insensitiveâ€ sÃ³ para str	Evita falso-negativo em campos textuais sem afetar tipos numÃ©ricos/datas.
expected is None â†’ filtro Ã© ignorado	Permite passar o parÃ¢metro sempre, sem precisar de condicionais na rota (`city: str
Docstring com exemplos	Facilita entendimento para quem implementar o prÃ³ximo adapter (SQL, Elastic etc.).

â€” e, quando vocÃª quiser acrescentar outro parÃ¢metro (date_from, venue_typeâ€¦), basta incluÃ­-lo no Query(...) da rota e repassar para list_partial sem alterar o contrato nem quebrar clientes.

## 4.Â CacheÂ comÂ RedisÂ paraÂ DesempenhoÂ 

> Â EstaÂ seÃ§Ã£oÂ explicaÂ *porÂ quÃª*Â eÂ *como*Â oÂ ProjetoÂ PrismaÂ usaÂ oÂ RedisÂ comoÂ cacheÂ deÂ respostas.Â ElaÂ complementaÂ oÂ passoâ€‘aâ€‘passoÂ detalhadoÂ jÃ¡Â descritoÂ noÂ Roadmap.

### 4.1Â VisÃ£oÂ geralÂ 

| Â Â                              | Â SemÂ cacheÂ                                                  | Â ComÂ RedisÂ (cacheâ€‘aside)Â                                                                                                |
| ------------------------------ | ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| FluxoÂ deÂ requisiÃ§Ã£o            | FastAPIÂ â†’Â ServiceÂ â†’Â APIÂ externaÂ ouÂ consultaÂ lentaÂ â†’Â Cliente | FastAPIÂ â†’Â **RedisÂ GET**Â â†’Â *HIT*?Â âœ”Â devolveÂ emÂ â—‰Â msÂ /Â *MISS*Â âœ–Â â†’Â ServiceÂ â†’Â APIÂ externaÂ â†’Â **RedisÂ SETEX**Â (TTL)Â â†’Â Cliente |
| LatÃªnciaÂ mÃ©dia                 | Â 100â€“800Â msÂ                                                 | Â â‰ˆ1â€“5Â msÂ apÃ³sÂ oÂ primeiroÂ acessoÂ                                                                                         |
| CargaÂ noÂ backend/APIÂ terceiros | 100Â %Â dasÂ requisiÃ§Ãµes                                       | 1Â requisiÃ§Ã£oÂ aÂ cadaÂ *TTL*                                                                                               |

**EstratÃ©gia:**Â usamosÂ oÂ padrÃ£oÂ *cacheâ€‘aside*Â (comumenteÂ chamadoÂ readâ€‘through):Â aÂ prÃ³priaÂ aplicaÃ§Ã£oÂ consultaÂ oÂ cacheÂ antesÂ deÂ executarÂ aÂ operaÃ§Ã£oÂ caraÂ eÂ gravaÂ oÂ resultadoÂ quandoÂ nÃ£oÂ encontraÂ aÂ chave.

---

### 4.2Â AbordagemÂ adotadaÂ noÂ cÃ³digo

| Â CamadaÂ                | Â ArquivoÂ /Â ElementoÂ                                                                                                     | Â DescriÃ§Ã£oÂ                                                                                              |
| ---------------------- | ----------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| **Provider**           | `app/deps.pyÂ â†’Â provide_redis()`                                                                                         | CriaÂ Â **umaÂ Ãºnica**Â instÃ¢nciaÂ `Redis.from_url(..)`Â Â eÂ aÂ reaproveitaÂ emÂ todoÂ oÂ appÂ                       |
| **DecoratorÂ genÃ©rico** | `app/utils/cache.pyÂ â†’Â cached_json()`                                                                                    | FunÃ§Ã£oÂ assÃ­ncronaÂ queÂ geraÂ chave,Â consultaÂ RedisÂ (`GET`),Â serializaÂ JSONÂ (`SETEX`)Â eÂ devolveÂ resultadoÂ  |
| **AplicaÃ§Ã£oÂ real**     | `app/api/v1/endpoints/local_info.py`Â <br>`app/api/v1/endpoints/forecast_info.py`Â <br>`app/api/v1/endpoints/eventos.py`Â  | EndpointsÂ decoradosÂ comÂ `@cached_json("prefix",Â ttl)`Â                                                   |
| **ConfiguraÃ§Ã£o**       | `.envÂ /Â config.pyÂ â†’Â REDIS_URL`                                                                                          | PermiteÂ apontarÂ paraÂ RedisÂ local,Â Docker,Â ouÂ nuvemÂ                                                      |

*ExemploÂ extraÃ­doÂ deÂ `local_info.py`:*

```python
@router.get("/local_info",Â response_model=LocalInfoResponse)
@cached_json("local-info",Â ttl=86400)Â Â Â Â Â Â Â #Â 24Â h
asyncÂ defÂ obter_local_info(location_name:Â str,Â service:Â AbstractLocalInfoServiceÂ =Â Depends(provide_local_info_service)):
Â Â Â Â infoÂ =Â awaitÂ service.get_by_name(location_name)
Â Â Â Â ifÂ infoÂ isÂ None:
Â Â Â Â Â Â Â Â raiseÂ HTTPException(404,Â "LocalÂ nÃ£oÂ encontrado")
Â Â Â Â returnÂ info
```

---

### 4.3Â OÂ queÂ podeÂ serÂ testado

| Â CasoÂ deÂ testeÂ                   | Â ObjetivoÂ                                                                           | Â FerramentasÂ sugeridasÂ                               |
| -------------------------------- | ----------------------------------------------------------------------------------- | ---------------------------------------------------- |
| **CacheÂ HITÂ vsÂ MISS**            | GarantirÂ queÂ aÂ primeiraÂ requisiÃ§Ã£oÂ (MISS)Â chamaÂ oÂ service/DBÂ eÂ aÂ segundaÂ (HIT)Â nÃ£oÂ  | `fakeredis`Â +Â pytestÂ â†’Â verificarÂ contadoresÂ /Â spiesÂ  |
| **TTLÂ expira**                   | ApÃ³sÂ `ttl`Â segundos,Â oÂ decoratorÂ deveÂ buscarÂ dadosÂ novamente                        | `freezegun`Â ouÂ `time.sleep`Â curtoÂ                    |
| **ChaveÂ Ãºnica**                  | RequisiÃ§ÃµesÂ comÂ parÃ¢metrosÂ diferentesÂ devemÂ gerarÂ chavesÂ diferentes                 | AssetÂ `redis.keys()`Â contÃ©mÂ osÂ hashesÂ esperadosÂ      |
| **FallbackÂ seÂ RedisÂ foraÂ doÂ ar** | AÂ aplicaÃ§Ã£oÂ nÃ£oÂ podeÂ quebrar:Â decoratorÂ executaÂ funÃ§Ã£oÂ originalÂ                     | MockÂ `provide_redis`Â paraÂ levantarÂ `ConnectionError` |

> Â **ObservaÃ§Ã£o:**Â nenhumÂ testeÂ precisaÂ deÂ RedisÂ real;Â useÂ `fakeredis.FakeRedis`Â eÂ faÃ§aÂ overrideÂ deÂ `provide_redis`.

---

### 4.4Â BoasÂ prÃ¡ticasÂ adotadas

\*Â **TTLÂ adequado**Â â†’Â previsÃ£oÂ doÂ tempoÂ 30Â min;Â geocodificaÃ§Ã£oÂ 24Â h;Â rankingsÂ deÂ eventosÂ 5â€“30Â s.
\*Â **ChaveÂ determinÃ­stica**Â â†’Â `prefix`Â +Â `hash(args,Â kwargs)`Â â€“Â minimizaÂ colisÃµesÂ eÂ simplificaÂ invalidar.
\*Â **FallbackÂ gracioso**Â â†’Â SeÂ RedisÂ cair,Â oÂ decoratorÂ sÃ³Â ignoraÂ oÂ cache.
\*Â **SerializaÃ§Ã£oÂ Ãºnica**Â â†’Â SempreÂ JSONÂ stringÂ (`default=str`)Â paraÂ uniformidade.

---

### 4.5Â OndeÂ alterarÂ casoÂ troqueÂ RedisÂ porÂ outroÂ cache

1.Â ImplementeÂ novoÂ providerÂ (`provide_memcached`,Â porÂ ex.)Â noÂ mesmoÂ formato.
2.Â AltereÂ `cached_json`Â paraÂ usarÂ esseÂ provider.
3.Â NenhumaÂ rotaÂ precisaÂ serÂ tocadaÂ â€“Â oÂ decoratorÂ cuidaÂ deÂ tudo.

---

**TL;DR:**Â adicionamosÂ RedisÂ paraÂ reduzirÂ latÃªnciaÂ eÂ cargaÂ sobreÂ APIsÂ externasÂ comÂ umÂ decoratorÂ plugâ€‘andâ€‘play;Â aÂ prÃ³priaÂ estruturaÂ permiteÂ testarÂ HIT/MISS,Â TTLÂ eÂ resiliÃªnciaÂ semÂ rodarÂ RedisÂ deÂ verdade.


## 4.Â CacheÂ comÂ RedisÂ paraÂ Desempenho

### 4.1Â VisÃ£oÂ geral

| Â Â             | Â SemÂ cacheÂ                                      | Â ComÂ RedisÂ (cacheâ€‘aside)Â                                                                                            |
| ------------- | ----------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| Fluxo         | FastAPIÂ â†’Â ServiceÂ â†’Â APIÂ externa/bancoÂ â†’Â Cliente | FastAPIÂ â†’Â **RedisÂ GET**Â â†’Â *HIT*?Â âœ”Â devolveÂ emÂ 1â€‘5Â msÂ /Â *MISS*Â âœ–Â â†’Â ServiceÂ â†’Â APIÂ externaÂ â†’Â **RedisÂ SETEX**Â â†’Â Cliente |
| LatÃªncia      | 400Â msÂ â€“Â 2Â s (dependendo da origem)             | 1Â â€‘Â 5Â msÂ apÃ³sÂ primeiroÂ MISS                                                                                         |
| CargaÂ externa | 100Â %Â dasÂ requests                              | â‰ƒÂ 1Â requestÂ porÂ TTL                                                                                                 |

> **EstratÃ©gia**: *cacheâ€‘aside* (tambÃ©m chamado *lazy loading*) â€“ apenas grava no Redis depois de consultar a fonte correta.

### 4.2Â OndeÂ oÂ cacheÂ estÃ¡Â sendoÂ usadoÂ noÂ cÃ³digo

| Endpoint                              | Prefixo / TTL           | Motivo do cache                                                                               | Local do cÃ³digo                                        |
| ------------------------------------- | ----------------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| `GETÂ /api/v1/local_info`              | `localâ€‘info` / **24â€¯h** | Resultado de geocodificaÃ§Ã£o Ã© praticamente estÃ¡tico; evita chamadas ao serviÃ§o externo.       | `app/api/v1/endpoints/eventos.py`Â â†’Â `obter_local_info` |
| `GETÂ /api/v1/forecast_info`           | `forecast` / **30â€¯min** | Chamada mockada mas, em produÃ§Ã£o, seria a API de clima (lenta/paga).                          | Mesmo arquivoÂ â†’Â `obter_forecast_info`                  |
| `GETÂ /api/v1/eventos/top/soon`        | `topâ€‘soon` / **10â€¯s**   | Ranking de "prÃ³ximos N" muda a cada poucos segundos; snapshot ultraâ€‘curto jÃ¡ satisfaz.        | Mesmo arquivoÂ â†’Â `eventos_proximos`                     |
| `GETÂ /api/v1/eventos/top/most-viewed` | `topâ€‘viewed` / **30â€¯s** | Ranking de mais vistos muda sÃ³ quando views incrementa; 30Â s equilibra frescor Ã— performance. | Mesmo arquivoÂ â†’Â `eventos_mais_vistos`                  |

Cada funÃ§Ã£o Ã© decorada com `@cached_json(<prefix>, ttl=<segundos>)`, implementado em **`app/utils/cache.py`**, que:

1. Gera uma chave determinÃ­stica com prefixo + params;
2. Faz `await redis.get(key)` â†’ **HIT** devolve JSON;
3. **MISS** executa a funÃ§Ã£o real, serializa e grava `SETEX key ttl value`.

### 4.3Â PorÂ queÂ *nÃ£o*Â aplicamosÂ cacheÂ emÂ todasÂ asÂ rotas?

| RazÃ£o                       | ExplicaÃ§Ã£o                                                                                                                  | Exemplo no projeto                                                                      |
| --------------------------- | --------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- |
| **NÃ£o idempotente**         | Rotas `POST`, `PUT`, `PATCH`, `DELETE` alteram estado. Cachear pode devolver versÃ£o desatualizada ou atrapalhar validaÃ§Ãµes. | `POSTÂ /api/v1/eventos` cria evento; *nÃ£o cacheamos*.                                    |
| **Alta cardinalidade**      | Muitas combinaÃ§Ãµes de queryâ€‘params criam milhÃµes de chaves ("keyâ€‘explosion").                                               | `GETÂ /api/v1/eventos?skip&limit&city` â€“ cada pÃ¡gina e cidade seria uma chave diferente. |
| **Dados volÃ¡teis**          | ConteÃºdo muda mais rÃ¡pido que um TTL razoÃ¡vel, tornando o cache inÃºtil.                                                     | Se tivÃ©ssemos um endpoint "/metricas/tempoâ€‘real" nÃ£o faria sentido cachear.             |
| **SeguranÃ§a e privacidade** | Respostas personalizadas por usuÃ¡rio nÃ£o devem ser compartilhadas entre sessÃµes anÃ´nimas.                                   | Rotas de autenticaÃ§Ã£o e perfis de usuÃ¡rio ficam fora do cache.                          |

> **Regra prÃ¡tica**: cache apenas `GET`s idempotentes, requisitados com alta frequÃªncia **e** cujo custo de geraÃ§Ã£o Ã© maior que 1â€‘2Â ms. Mantenha o restante simples para evitar inconsistÃªncias.

### 4.4Â OÂ queÂ podeÂ serÂ testado

1. **HITÂ Ã—Â MISS** â€” invoque o endpoint duas vezes; a segunda deve ser mais rÃ¡pida e nÃ£o acionar o service.
2. **TTL** â€” apÃ³s expirar, a prÃ³xima chamada volta a ser MISS.
3. **KeyÂ uniqueness** â€” parÃ¢metros diferentes geram chaves diferentes e nÃ£o se sobrepÃµem.
4. **Fallback se Redis cair** â€” simule `ConnectionError` (monkeypatch em `provide_redis`) e verifique que o endpoint ainda responde, sÃ³ que sem cache.
5. **Isolamento em testes** â€” use `fakeredis` via override de `provide_redis` para evitar sideâ€‘effects.

```python
# exemplo de teste HIT/MISS com fakeredis
async def test_cache_hit(client, fake_redis):
    resp1 = await client.get("/api/v1/local_info?location_name=recife")
    assert resp1.status_code == 200

    # segunda chamada deve vir do cache
    resp2 = await client.get("/api/v1/local_info?location_name=recife")
    assert resp2.json() == resp1.json()
    # opcional: use fake_redis.get(key) para confirmar presenÃ§a do valor
```

Essa abordagem garante respostas rÃ¡pidas onde realmente importa, sem aumentar a complexidade nem comprometer a consistÃªncia das demais rotas.

Pipeline de IntegraÃ§Ã£o ContÃ­nua (CI)

Este repositÃ³rio possui um GitHub ActionsÂ workflow (.github/workflows/ci.yml) que automatiza verificaÃ§Ãµes de qualidade toda vez que o cÃ³digo muda. O pipeline protege aÂ main, encurta o ciclo de feedback para colaboradores e documenta a saÃºde do projeto de forma reproduzÃ­vel.

Por que investir em CI?

ConfianÃ§a antes do mergeÂ â€“ todoÂ push ou Pull Request (PR) Ã© construÃ­do e testado exatamente como em produÃ§Ã£o.

Feedback rÃ¡pidoÂ â€“ erros de estilo, problemas de tipo ou testes falhando aparecem em minutos.

Cobertura multiplataformaÂ â€“ a matriz executa Ubuntu eÂ Windows em PythonÂ 3.10Â â†’Â 3.12, revelando bugs especÃ­ficos de SO.

Estilo e seguranÃ§a automÃ¡ticosÂ â€“ linters e scanners de seguranÃ§a comentam direto no PR, liberando os revisores para focarem na regra de negÃ³cio.

Qualidade mensurÃ¡velÂ â€“ relatÃ³rios de cobertura acompanham a evoluÃ§Ã£o dos testes ao longo do tempo.

Gatilhos do workflow

Evento

Quando dispara

push

Qualquer commit em main ou develop

pull_request

Novos PRs e cada atualizaÃ§Ã£o neles

Rodar nos dois eventos garante que commits isolados fiquem verdes eÂ que o resultado final do merge tambÃ©m passe.

PermissÃµes mÃ­nimas

permissions:
  contents: read          # clonar o repositÃ³rio
  pull-requests: write    # permite que o Ruff / Codecov escrevam comentÃ¡rios

Aplicar apenas o necessÃ¡rio segue oÂ princÃ­pio do menor privilÃ©gioÂ e reduz riscos na cadeia de suprimentos.

Matriz de execuÃ§Ã£o

Eixo

Valores

Objetivo

OS

ubuntu-latest, windows-latest

Detectar problemas de path/caseâ€‘sensitive

Python

3.10, 3.11, 3.12

Garantir compatibilidade futura

O fail-fast: true aborta os demais jobs da matriz apÃ³s a primeira falha, economizando minutos de build.

Passo a passo

#

Etapa

O que faz

Por que importa

1ï¸âƒ£

Checkout (actions/checkout)

Clona o cÃ³digo

Torna o fonte disponÃ­vel no runner

2ï¸âƒ£

Setup Python (actions/setup-python)

Instala a versÃ£o da matriz e restaura cache deÂ pip

Ambiente homogÃªneo

3ï¸âƒ£

Cache Poetry + venv

Restaura cache do Poetry e virtualenv se oÂ poetry.lock nÃ£o mudou

Reduz o tempo de instalaÃ§Ã£o

4ï¸âƒ£

Instalar dependÃªncias

Atualiza pip, instala Poetry e executa poetry install --with dev

Disponibiliza pytest, Ruff etc.

5ï¸âƒ£

Ruff

Lint + formataÃ§Ã£o, gera comentÃ¡rios inline

Garante PEPÂ 8, detecta imports nÃ£o usados e sintaxe antiga

6ï¸âƒ£

PyUpgrade

Sugere modernizaÃ§Ã£o para PythonÂ 3.12

MantÃ©m o cÃ³digo atual

7ï¸âƒ£

MyPy

Checagem estrita de tipos

Encontra erros de contrato antes da execuÃ§Ã£o

8ï¸âƒ£

Bandit

Linter de seguranÃ§a

Alerta para eval, md5, injeÃ§Ãµesâ€¦

9ï¸âƒ£

Pytest

Roda a suÃ­te com -x (failâ€‘fast) e cobertura â‰¥Â 80Â %

Evita regressÃµes

ğŸ”Ÿ

Codecov (opcional)

Faz upload do coverage.xml e comenta diffs

MÃ©trica de qualidade visÃ­vel

Cobertura mÃ­nimaÂ â€“ --cov-fail-under=80 falha o job se a cobertura total cair abaixo de 80Â %. Ajuste conforme o projeto amadurece.

Resumo das ferramentas

Ferramenta

Categoria

Comando local

Valor agregado

Ruff

Estilo / anÃ¡lise estÃ¡tica bÃ¡sica

poetry run ruff check .

PEPÂ 8, imports, docstrings

PyUpgrade

ModernizaÃ§Ã£o de sintaxe

pyupgrade --py312-plus $(git ls-files '*.py')

Remove legados

MyPy

Tipagem

poetry run mypy app

Previne erros de tipo

Bandit

SeguranÃ§a

poetry run bandit -q -r app -lll

Detecta padrÃµes inseguros

Pytest

Testes e cobertura

poetry run pytest -x --cov=app

Garante comportamento

Codecov

Cobertura diferencial

AutomÃ¡tico pelo Action

Badge + comentÃ¡rios

Execute os mesmos comandos localmente antes doÂ pushÂ para obter feedback idÃªntico ao CI:

poetry install --with dev --no-interaction
poetry run ruff check .
pyupgrade --py312-plus $(git ls-files '*.py')
poetry run mypy app
poetry run bandit -q -r app -lll
poetry run pytest -x --cov=app --cov-fail-under=80

PrÃ³ximos passos possÃ­veis

Melhoria

BenefÃ­cio

ObservaÃ§Ã£o

CodeQL

AnÃ¡lise de fluxo de dados (SQLi, PathÂ Traversal)

GrÃ¡tis em repositÃ³rios pÃºblicos

Dependabot

PRs automÃ¡ticos para libs vulnerÃ¡veis

dependabot.yml semanal

preâ€‘commit

Mesmos linters rodando no hook local

Evita rodadas de CI perdidas

Build de Docker

Publica imagem em cada tag

docker/build-push-action

Releaseâ€‘drafter

Gera CHANGELOG automaticamente

Ajuda no versionamento

Artefatos

Armazena relatÃ³rios HTML, wheels

actions/upload-artifact

NotificaÃ§Ãµes Slack

Status do CI no chat

8398a7/action-slack

ReferÃªncia de configuraÃ§Ã£o (trecho)

[tool.ruff]
line-length = 250

[tool.ruff.lint]
select = ["E", "F", "I", "UP"]
ignore = ["E241", "E302", "E231", "E226", "E261", "E262", "E305", "E251", "I001"]
extend-ignore = ["D203", "D213"]
preview = true

[tool.mypy]
python_version = "3.12"
strict = true
ignore_missing_imports = true

Simulando o workflow localmente (opcional)

Com act:

act push --job test

O act roda um contÃªiner Docker que imita o ubuntu-latest, devolvendo resultados quase idÃªnticos ao CI real sem esperar na fila.

Bom cÃ³digoÂ â€“ e aproveite a rede de seguranÃ§a! ğŸš€

ğŸ“Š Observabilidade e Logs
Este projeto conta com um sistema estruturado e extensÃ­vel de logs usando structlog, permitindo registros claros, padronizados e prontos para ferramentas de monitoramento, auditoria e diagnÃ³stico.

âœ… Funcionalidades Implementadas
Log estruturado com structlog, no formato JSON.

Middleware de logging que registra todas as requisiÃ§Ãµes HTTP com:

MÃ©todo (GET, POST, etc.)

Caminho (/api/v1/...)

CÃ³digo de status da resposta (200, 404, etc.)

DuraÃ§Ã£o da requisiÃ§Ã£o (em segundos)

IP do cliente

CabeÃ§alho User-Agent

UsuÃ¡rio autenticado (quando houver)

Contexto global por requisiÃ§Ã£o com ContextVar (request_user) para registrar o nome do usuÃ¡rio logado ao longo da requisiÃ§Ã£o.

Filtragem de rotas internas: rotas como /docs, /redoc e /openapi.json sÃ£o ignoradas nos logs para evitar ruÃ­do.

ğŸ§± Estrutura de Arquivos
Arquivo	FunÃ§Ã£o
app/core/logging_config.py	ConfiguraÃ§Ã£o do structlog (formato JSON, timestamp, nÃ­vel de log etc.)
app/core/contextvars.py	Define a variÃ¡vel request_user para guardar o usuÃ¡rio da requisiÃ§Ã£o
app/services/auth_service.py	Define o request_user apÃ³s autenticaÃ§Ã£o via token
app/middleware/logging_middleware.py	Middleware que registra cada requisiÃ§Ã£o HTTP, incluindo usuÃ¡rio
Diversos mock_*.py, event_mem.py, deps.py	Logs internos de operaÃ§Ãµes simuladas e repositÃ³rios

ğŸ§© Exemplo de log gerado
json
Copiar
Editar
{
  "event": "HTTP request log",
  "method": "GET",
  "path": "/api/v1/eventos",
  "status_code": 200,
  "duration": 0.015,
  "client": "127.0.0.1",
  "user_agent": "Mozilla/5.0...",
  "user": "alice",
  "timestamp": "2025-06-15T18:00:00Z",
  "level": "info"
}
ğŸ›  Como estender
VocÃª pode ampliar o sistema de logs com as seguintes prÃ¡ticas:

Logar o tamanho da resposta (bytes).

Registrar os corpos da requisiÃ§Ã£o/resposta (Ãºtil para debugging â€” evite dados sensÃ­veis).

Enviar os logs para ferramentas externas como Loki, ELK (Elasticsearch + Logstash + Kibana) ou DataDog.

Separar logs de erro em arquivos distintos.

Adicionar um ID de correlaÃ§Ã£o por requisiÃ§Ã£o para rastrear logs em microsserviÃ§os.

ğŸ“Œ Dicas
Os logs sÃ£o estruturados e podem ser consumidos facilmente por ferramentas como Grafana, Prometheus, Loki ou ElasticSearch.

Utilize logger.info(...), logger.warning(...) e logger.error(...) em qualquer ponto do sistema: a estrutura jÃ¡ estÃ¡ preparada para manter os logs padronizados e legÃ­veis.

## ğŸ“¡ WebSockets, Upload e Download de Arquivos

Esta seÃ§Ã£o descreve como foram implementadas as funcionalidades relacionadas a tempo real e manipulaÃ§Ã£o de arquivos no projeto, detalhando o uso de WebSockets e rotas para upload e download de arquivos.

### 1. WebSockets

O WebSocket permite uma comunicaÃ§Ã£o interativa e em tempo real entre o servidor e os clientes conectados, possibilitando notificaÃ§Ãµes instantÃ¢neas, progresso em tempo real e atualizaÃ§Ãµes de dashboards.

#### Funcionalidades via WebSocket:

* **Upload de Eventos em Tempo Real:**

  * NotificaÃ§Ãµes de progresso linha a linha durante o upload.
  * IndicaÃ§Ã£o imediata de erros por linha.
  * Mensagem final ao tÃ©rmino da importaÃ§Ã£o.

* **Dashboard ao Vivo:**

  * Contagem de eventos atualizada automaticamente sem necessidade de polling HTTP.
  * NÃºmero de usuÃ¡rios conectados atualizado em tempo real.

* **Logs e Status de Tarefas Longas:**

  * Envio contÃ­nuo de logs ou mensagens de status enquanto tarefas sÃ£o executadas.

* **NotificaÃ§Ãµes Administrativas:**

  * Avisos aos administradores sempre que novos eventos forem criados ou houver alteraÃ§Ãµes massivas.

### 2. Upload de Eventos via CSV

Implementado um endpoint `/eventos/upload` para permitir o upload de arquivos CSV contendo mÃºltiplos eventos. Cada linha do CSV representa um evento completo que serÃ¡ processado e adicionado ao repositÃ³rio.

* Formato esperado do CSV:

```csv
title,description,event_date,city,participants,local_info
Evento 1,DescriÃ§Ã£o do evento,2025-07-01T10:00:00,Recife,Alice;Bob,"{\"location_name\": \"AuditÃ³rio Central\", \"capacity\": 300, \"venue_type\": \"AuditÃ³rio\", \"is_accessible\": true, \"address\": \"Rua Exemplo, 123\", \"past_events\": [], \"manually_edited\": false}"
```

* Durante o upload:

  * ValidaÃ§Ã£o das linhas do arquivo.
  * Retorno detalhado via WebSocket sobre o status e possÃ­veis erros.

### 3. Download de Eventos em JSON

Foi criado um endpoint `/eventos/download` que permite baixar os eventos existentes no repositÃ³rio em formato JSON.

* Exemplo do endpoint:

```http
GET /api/v1/eventos/download
```

* A resposta serÃ¡ um arquivo JSON contendo todos os eventos cadastrados:

```json
[
  {
    "title": "Evento 1",
    "description": "DescriÃ§Ã£o do evento",
    "event_date": "2025-07-01T10:00:00",
    "city": "Recife",
    "participants": ["Alice", "Bob"],
    "local_info": {
      "location_name": "AuditÃ³rio Central",
      "capacity": 300,
      "venue_type": "AuditÃ³rio",
      "is_accessible": true,
      "address": "Rua Exemplo, 123",
      "past_events": [],
      "manually_edited": false
    }
  }
  // Mais eventos...
]
```

Essas funcionalidades ampliam significativamente a interatividade e eficiÃªncia do projeto, oferecendo feedback instantÃ¢neo e facilitando operaÃ§Ãµes em lote por meio de arquivos.

ğŸ§ª Testes Automatizados
O projeto utiliza testes automatizados com pytest para garantir a confiabilidade e robustez do sistema, garantindo tambÃ©m que as novas funcionalidades nÃ£o quebrem implementaÃ§Ãµes existentes. Os testes abrangem tanto testes unitÃ¡rios quanto testes de integraÃ§Ã£o, com mediÃ§Ã£o de cobertura utilizando pytest-cov.

ğŸ”§ DecisÃµes tÃ©cnicas para os testes
Durante o desenvolvimento dos testes, foram encontrados cenÃ¡rios especÃ­ficos que geraram erros de execuÃ§Ã£o, especialmente relacionados Ã  criaÃ§Ã£o de tarefas assÃ­ncronas usando a funÃ§Ã£o asyncio.create_task() em rotas sÃ­ncronas.

Para resolver isso mantendo a integridade do cÃ³digo principal (o sistema jÃ¡ estava em produÃ§Ã£o e funcionando corretamente), foi tomada a decisÃ£o de ajustar exclusivamente o comportamento dos testes ao invÃ©s do cÃ³digo da aplicaÃ§Ã£o.

Motivos da decisÃ£o:

O sistema em produÃ§Ã£o estava funcionando corretamente.

AlteraÃ§Ãµes no cÃ³digo principal poderiam impactar negativamente o ambiente produtivo.

O problema era especÃ­fico dos testes, que executavam em contextos sÃ­ncronos onde nÃ£o havia um event loop ativo.

âš™ï¸ AlteraÃ§Ã£o Realizada nos Testes
A alteraÃ§Ã£o foi feita diretamente na configuraÃ§Ã£o dos testes (no arquivo tests/conftest.py), utilizando o recurso monkeypatch do pytest para substituir a funÃ§Ã£o problemÃ¡tica durante a execuÃ§Ã£o dos testes:

FunÃ§Ã£o substituÃ­da: asyncio.create_task

Motivo: Durante testes, esta funÃ§Ã£o lanÃ§ava RuntimeError: no running event loop, jÃ¡ que o pytest executava as chamadas sÃ­ncronas em um contexto sem event loop ativo.

Antes:
python
Copiar
Editar
asyncio.create_task(coroutine)
Depois (apenas nos testes):
python
Copiar
Editar
def _safe_create_task(coro, *args, **kwargs):
    try:
        loop = asyncio.get_running_loop()
        return loop.create_task(coro, *args, **kwargs)
    except RuntimeError:
        _loop = asyncio.new_event_loop()
        try:
            _loop.run_until_complete(coro)
        finally:
            _loop.close()

        class _DummyTask:
            def cancel(self):
                pass
        return _DummyTask()

monkeypatch.setattr(asyncio, "create_task", _safe_create_task, raising=True)
Essa soluÃ§Ã£o garante que:

Caso jÃ¡ exista um event loop ativo, o comportamento padrÃ£o de asyncio.create_task() Ã© mantido.

Caso contrÃ¡rio (cenÃ¡rio de testes sÃ­ncronos), Ã© criado um novo event loop temporÃ¡rio para executar o coroutine diretamente, garantindo a execuÃ§Ã£o e evitando erros durante o teste.

ğŸ“Œ FunÃ§Ãµes Impactadas e Testes Relacionados
As funÃ§Ãµes do sistema afetadas e ajustadas especificamente para testes foram:

put_events (rota /eventos), que dispara tarefas assÃ­ncronas como notificaÃ§Ãµes WebSocket.

post_create_event (rota POST /eventos), que dispara notificaÃ§Ãµes assÃ­ncronas apÃ³s criar eventos.

Essas funÃ§Ãµes sÃ£o testadas pelos seguintes testes, entre outros:

test_create_event_valid

test_replace_all_events

test_update_event_type_valid

test_update_local_info

test_atualizar_forecast_info

Dessa forma, os testes foram corrigidos sem nenhuma alteraÃ§Ã£o funcional ou estrutural no cÃ³digo da aplicaÃ§Ã£o, preservando o comportamento original do sistema e garantindo testes estÃ¡veis e confiÃ¡veis.

migrations

2. Recrie a migraÃ§Ã£o corretamente
Como a migraÃ§Ã£o anterior nÃ£o criou a tabela events, vocÃª precisa apagar essa versÃ£o e gerar outra:

bash
Copiar
Editar
# 1. Apague o migration antigo (ou renomeie para backup)
rm migrations/versions/*.py  # cuidado: isso remove TODAS as versÃµes de migraÃ§Ã£o

# 2. Gere nova migraÃ§Ã£o com os modelos agora corretamente importados
alembic revision --autogenerate -m "create tables"

# 3. Aplique a nova migraÃ§Ã£o
alembic upgrade head

Esse erro aconteceu porque vocÃª deletou ou removeu os arquivos da pasta migrations/versions/, mas o banco de dados ainda estÃ¡ com o controle interno apontando para a versÃ£o 'e69fdb78a658'.

âœ… Como resolver isso corretamente
ğŸ“Œ Objetivo:
Resetar o histÃ³rico de migraÃ§Ãµes para sincronizar o banco com a nova estrutura de arquivos.

âœ… Etapas para resolver:
1. Apague a tabela de controle de migraÃ§Ã£o (alembic_version)
Essa tabela fica no seu banco de dados e guarda qual versÃ£o estÃ¡ atualmente aplicada. Execute no seu banco (via psql, DBeaver, pgAdmin, ou terminal):

sql
Copiar
Editar
DROP TABLE alembic_version;
Isso permite que o Alembic recrie o controle corretamente com a nova versÃ£o.

2. Crie uma nova migraÃ§Ã£o do zero
Com os modelos devidamente importados no migrations/env.py, rode:

bash
Copiar
Editar
alembic revision --autogenerate -m "create all tables"
Isso vai gerar um novo arquivo de migraÃ§Ã£o em migrations/versions/.

3. Aplique essa nova migraÃ§Ã£o ao banco
bash
Copiar
Editar
alembic upgrade head
Se tudo estiver correto, agora a tabela events e as outras (local_infos, forecast_infos) serÃ£o criadas.
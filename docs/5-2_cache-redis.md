# Em construÃ§Ã£o
# ğŸš€ Cache com Redis para Melhor Desempenho

Este documento descreve como o projeto FastTrackAPI utiliza o Redis para melhorar significativamente o desempenho das requisiÃ§Ãµes HTTP, reduzindo latÃªncia e carga sobre serviÃ§os externos e bancos de dados. Utilizamos o padrÃ£o **cache-aside** (tambÃ©m conhecido como lazy loading), que verifica o cache antes de consultar serviÃ§os externos ou realizar operaÃ§Ãµes custosas.

---

## ğŸ”„ VisÃ£o Geral

| Aspecto             | Sem cache                             | Com Redis (cache-aside)                                                           |
| ------------------- | ------------------------------------- | --------------------------------------------------------------------------------- |
| Fluxo da requisiÃ§Ã£o | FastAPI â†’ ServiÃ§o â†’ Banco/API externa | FastAPI â†’ **Redis GET** â†’ HIT âœ” (retorno rÃ¡pido) / MISS âœ– â†’ ServiÃ§o â†’ Redis SETEX |
| LatÃªncia mÃ©dia      | 400ms a 2s (dependendo da origem)     | 1ms a 5ms apÃ³s primeiro MISS                                                      |
| Carga externa       | 100% das requisiÃ§Ãµes                  | 1 requisiÃ§Ã£o por TTL                                                              |

| Â Â                              | Â SemÂ cacheÂ                                                  | Â ComÂ RedisÂ (cacheâ€‘aside)Â                                                                                                |
| ------------------------------ | ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| FluxoÂ deÂ requisiÃ§Ã£o            | FastAPIÂ â†’Â ServiceÂ â†’Â APIÂ externaÂ ouÂ consultaÂ lentaÂ â†’Â Cliente | FastAPIÂ â†’Â **RedisÂ GET**Â â†’Â *HIT*?Â âœ”Â devolveÂ emÂ â—‰Â msÂ /Â *MISS*Â âœ–Â â†’Â ServiceÂ â†’Â APIÂ externaÂ â†’Â **RedisÂ SETEX**Â (TTL)Â â†’Â Cliente |
| LatÃªnciaÂ mÃ©dia                 | Â 100â€“800Â msÂ                                                 | Â â‰ˆ1â€“5Â msÂ apÃ³sÂ oÂ primeiroÂ acessoÂ                                                                                         |
| CargaÂ noÂ backend/APIÂ terceiros | 100Â %Â dasÂ requisiÃ§Ãµes                                       | 1Â requisiÃ§Ã£oÂ aÂ cadaÂ *TTL*                                                                                               |

**EstratÃ©gia:**Â usamosÂ oÂ padrÃ£oÂ *cacheâ€‘aside*Â (comumenteÂ chamadoÂ readâ€‘through):Â aÂ prÃ³priaÂ aplicaÃ§Ã£oÂ consultaÂ oÂ cacheÂ antesÂ deÂ executarÂ aÂ operaÃ§Ã£oÂ caraÂ eÂ gravaÂ oÂ resultadoÂ quandoÂ nÃ£oÂ encontraÂ aÂ chave.

| Â Â             | Â SemÂ cacheÂ                                      | Â ComÂ RedisÂ (cacheâ€‘aside)Â                                                                                            |
| ------------- | ----------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| Fluxo         | FastAPIÂ â†’Â ServiceÂ â†’Â APIÂ externa/bancoÂ â†’Â Cliente | FastAPIÂ â†’Â **RedisÂ GET**Â â†’Â *HIT*?Â âœ”Â devolveÂ emÂ 1â€‘5Â msÂ /Â *MISS*Â âœ–Â â†’Â ServiceÂ â†’Â APIÂ externaÂ â†’Â **RedisÂ SETEX**Â â†’Â Cliente |
| LatÃªncia      | 400Â msÂ â€“Â 2Â s (dependendo da origem)             | 1Â â€‘Â 5Â msÂ apÃ³sÂ primeiroÂ MISS                                                                                         |
| CargaÂ externa | 100Â %Â dasÂ requests                              | â‰ƒÂ 1Â requestÂ porÂ TTL                                                                                                 |

> **EstratÃ©gia**: *cacheâ€‘aside* (tambÃ©m chamado *lazy loading*) â€“ apenas grava no Redis depois de consultar a fonte correta.

---

## âš™ï¸ ImplementaÃ§Ã£o no CÃ³digo

| Â CamadaÂ                | Â ArquivoÂ /Â ElementoÂ                                                                                                     | Â DescriÃ§Ã£oÂ                                                                                              |
| ---------------------- | ----------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| **Provider**           | `app/deps.pyÂ â†’Â provide_redis()`                                                                                         | CriaÂ Â **umaÂ Ãºnica**Â instÃ¢nciaÂ `Redis.from_url(..)`Â Â eÂ aÂ reaproveitaÂ emÂ todoÂ oÂ appÂ                       |
| **DecoratorÂ genÃ©rico** | `app/utils/cache.pyÂ â†’Â cached_json()`                                                                                    | FunÃ§Ã£oÂ assÃ­ncronaÂ queÂ geraÂ chave,Â consultaÂ RedisÂ (`GET`),Â serializaÂ JSONÂ (`SETEX`)Â eÂ devolveÂ resultadoÂ  |
| **AplicaÃ§Ã£oÂ real**     | `app/api/v1/endpoints/local_info.py`Â <br>`app/api/v1/endpoints/forecast_info.py`Â <br>`app/api/v1/endpoints/eventos.py`Â  | EndpointsÂ decoradosÂ comÂ `@cached_json("prefix",Â ttl)`Â                                                   |
| **ConfiguraÃ§Ã£o**       | `.envÂ /Â config.pyÂ â†’Â REDIS_URL`                                                                                          | PermiteÂ apontarÂ paraÂ RedisÂ local,Â Docker,Â ouÂ nuvemÂ                                                      |

### Decorador GenÃ©rico

Utilizamos um decorador genÃ©rico, `cached_json`, que automatiza todo o processo:

* Gera uma chave Ãºnica para cada requisiÃ§Ã£o.
* Verifica se o resultado jÃ¡ existe no cache (Redis GET).
* Caso contrÃ¡rio (MISS), chama o serviÃ§o original, armazena o resultado (Redis SETEX) e retorna ao cliente.

Exemplo no cÃ³digo:

```python
@cached_json("local-info", ttl=86400)
async def obter_local_info(location_name: str, service: AbstractLocalInfoService = Depends(provide_local_info_service)):
    info = await service.get_by_name(location_name)
    if info is None:
        raise HTTPException(404, "Local nÃ£o encontrado")
    return info
```

### 4.2Â OndeÂ oÂ cacheÂ estÃ¡Â sendoÂ usadoÂ noÂ cÃ³digo

| Endpoint                              | Prefixo / TTL           | Motivo do cache                                                                               | Local do cÃ³digo                                        |
| ------------------------------------- | ----------------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| `GETÂ /api/v1/local_info`              | `localâ€‘info` / **24â€¯h** | Resultado de geocodificaÃ§Ã£o Ã© praticamente estÃ¡tico; evita chamadas ao serviÃ§o externo.       | `app/api/v1/endpoints/eventos.py`Â â†’Â `obter_local_info` |
| `GETÂ /api/v1/forecast_info`           | `forecast` / **30â€¯min** | Chamada mockada mas, em produÃ§Ã£o, seria a API de clima (lenta/paga).                          | Mesmo arquivoÂ â†’Â `obter_forecast_info`                  |
| `GETÂ /api/v1/eventos/top/soon`        | `topâ€‘soon` / **10â€¯s**   | Ranking de "prÃ³ximos N" muda a cada poucos segundos; snapshot ultraâ€‘curto jÃ¡ satisfaz.        | Mesmo arquivoÂ â†’Â `eventos_proximos`                     |
| `GETÂ /api/v1/eventos/top/most-viewed` | `topâ€‘viewed` / **30â€¯s** | Ranking de mais vistos muda sÃ³ quando views incrementa; 30Â s equilibra frescor Ã— performance. | Mesmo arquivoÂ â†’Â `eventos_mais_vistos`                  |

Cada funÃ§Ã£o Ã© decorada com `@cached_json(<prefix>, ttl=<segundos>)`, implementado em **`app/utils/cache.py`**, que:

1. Gera uma chave determinÃ­stica com prefixo + params;
2. Faz `await redis.get(key)` â†’ **HIT** devolve JSON;
3. **MISS** executa a funÃ§Ã£o real, serializa e grava `SETEX key ttl value`.

### 4.3Â PorÂ queÂ *nÃ£o*Â aplicamosÂ cacheÂ emÂ todasÂ asÂ rotas?

| RazÃ£o                       | ExplicaÃ§Ã£o                                                                                                                  | Exemplo no projeto                                                                      |
| --------------------------- | --------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- |
| **NÃ£o idempotente**         | Rotas `POST`, `PUT`, `PATCH`, `DELETE` alteram estado. Cachear pode devolver versÃ£o desatualizada ou atrapalhar validaÃ§Ãµes. | `POSTÂ /api/v1/eventos` cria evento; *nÃ£o cacheamos*.                                    |
| **Alta cardinalidade**      | Muitas combinaÃ§Ãµes de queryâ€‘params criam milhÃµes de chaves ("keyâ€‘explosion").                                               | `GETÂ /api/v1/eventos?skip&limit&city` â€“ cada pÃ¡gina e cidade seria uma chave diferente. |
| **Dados volÃ¡teis**          | ConteÃºdo muda mais rÃ¡pido que um TTL razoÃ¡vel, tornando o cache inÃºtil.                                                     | Se tivÃ©ssemos um endpoint "/metricas/tempoâ€‘real" nÃ£o faria sentido cachear.             |
| **SeguranÃ§a e privacidade** | Respostas personalizadas por usuÃ¡rio nÃ£o devem ser compartilhadas entre sessÃµes anÃ´nimas.                                   | Rotas de autenticaÃ§Ã£o e perfis de usuÃ¡rio ficam fora do cache.                          |

> **Regra prÃ¡tica**: cache apenas `GET`s idempotentes, requisitados com alta frequÃªncia **e** cujo custo de geraÃ§Ã£o Ã© maior que 1â€‘2Â ms. Mantenha o restante simples para evitar inconsistÃªncias.

---

## ğŸ—ƒï¸ ConfiguraÃ§Ã£o do Redis

A URL do Redis Ã© configurada via variÃ¡vel de ambiente, permitindo flexibilidade entre ambientes:

```ini
# .env
REDIS_URL=redis://localhost:6379/0

# .env.prod
REDIS_URL=redis://redis:6379/0
```

---

## âœ… BenefÃ­cios

* **ReduÃ§Ã£o drÃ¡stica na latÃªncia:** RequisiÃ§Ãµes comuns passam a ser respondidas em milissegundos.
* **Menor carga em serviÃ§os externos:** Reduz a frequÃªncia de chamadas custosas a APIs externas.
* **Escalabilidade facilitada:** Redis pode ser facilmente substituÃ­do por serviÃ§os gerenciados como AWS ElastiCache sem alteraÃ§Ã£o no cÃ³digo.
* **Alta disponibilidade:** Caso o Redis falhe, o sistema continua funcionando normalmente, apenas ignorando o cache.

---

## 4.5Â OndeÂ alterarÂ casoÂ troqueÂ RedisÂ porÂ outroÂ cache

1.Â ImplementeÂ novoÂ providerÂ (`provide_memcached`,Â porÂ ex.)Â noÂ mesmoÂ formato.
2.Â AltereÂ `cached_json`Â paraÂ usarÂ esseÂ provider.
3.Â NenhumaÂ rotaÂ precisaÂ serÂ tocadaÂ â€“Â oÂ decoratorÂ cuidaÂ deÂ tudo.

---

**TL;DR:**Â adicionamosÂ RedisÂ paraÂ reduzirÂ latÃªnciaÂ eÂ cargaÂ sobreÂ APIsÂ externasÂ comÂ umÂ decoratorÂ plugâ€‘andâ€‘play;Â aÂ prÃ³priaÂ estruturaÂ permiteÂ testarÂ HIT/MISS,Â TTLÂ eÂ resiliÃªnciaÂ semÂ rodarÂ RedisÂ deÂ verdade.

---

## ğŸ§ª Testes com Cache

Testes essenciais que podem ser realizados:

* **HIT vs MISS:** Garantir que a segunda requisiÃ§Ã£o retorna imediatamente do cache.
* **ExpiraÃ§Ã£o de TTL:** Confirmar que apÃ³s o tempo configurado, o cache expira e busca novamente.
* **Falha de Redis:** O sistema nÃ£o deve falhar; apenas opera sem cache.

| Â CasoÂ deÂ testeÂ                   | Â ObjetivoÂ                                                                           | Â FerramentasÂ sugeridasÂ                               |
| -------------------------------- | ----------------------------------------------------------------------------------- | ---------------------------------------------------- |
| **CacheÂ HITÂ vsÂ MISS**            | GarantirÂ queÂ aÂ primeiraÂ requisiÃ§Ã£oÂ (MISS)Â chamaÂ oÂ service/DBÂ eÂ aÂ segundaÂ (HIT)Â nÃ£oÂ  | `fakeredis`Â +Â pytestÂ â†’Â verificarÂ contadoresÂ /Â spiesÂ  |
| **TTLÂ expira**                   | ApÃ³sÂ `ttl`Â segundos,Â oÂ decoratorÂ deveÂ buscarÂ dadosÂ novamente                        | `freezegun`Â ouÂ `time.sleep`Â curtoÂ                    |
| **ChaveÂ Ãºnica**                  | RequisiÃ§ÃµesÂ comÂ parÃ¢metrosÂ diferentesÂ devemÂ gerarÂ chavesÂ diferentes                 | AssetÂ `redis.keys()`Â contÃ©mÂ osÂ hashesÂ esperadosÂ      |
| **FallbackÂ seÂ RedisÂ foraÂ doÂ ar** | AÂ aplicaÃ§Ã£oÂ nÃ£oÂ podeÂ quebrar:Â decoratorÂ executaÂ funÃ§Ã£oÂ originalÂ                     | MockÂ `provide_redis`Â paraÂ levantarÂ `ConnectionError` |

> Â **ObservaÃ§Ã£o:**Â nenhumÂ testeÂ precisaÂ deÂ RedisÂ real;Â useÂ `fakeredis.FakeRedis`Â eÂ faÃ§aÂ overrideÂ deÂ `provide_redis`.

Exemplo de teste com `fakeredis`:

```python
async def test_cache_hit(client, fake_redis):
    resp1 = await client.get("/api/v1/local_info?location_name=recife")
    assert resp1.status_code == 200

    resp2 = await client.get("/api/v1/local_info?location_name=recife")
    assert resp2.json() == resp1.json()
```

1. **HITÂ Ã—Â MISS** â€” invoque o endpoint duas vezes; a segunda deve ser mais rÃ¡pida e nÃ£o acionar o service.
2. **TTL** â€” apÃ³s expirar, a prÃ³xima chamada volta a ser MISS.
3. **KeyÂ uniqueness** â€” parÃ¢metros diferentes geram chaves diferentes e nÃ£o se sobrepÃµem.
4. **Fallback se Redis cair** â€” simule `ConnectionError` (monkeypatch em `provide_redis`) e verifique que o endpoint ainda responde, sÃ³ que sem cache.
5. **Isolamento em testes** â€” use `fakeredis` via override de `provide_redis` para evitar sideâ€‘effects.

```python
# exemplo de teste HIT/MISS com fakeredis
async def test_cache_hit(client, fake_redis):
    resp1 = await client.get("/api/v1/local_info?location_name=recife")
    assert resp1.status_code == 200

    # segunda chamada deve vir do cache
    resp2 = await client.get("/api/v1/local_info?location_name=recife")
    assert resp2.json() == resp1.json()
    # opcional: use fake_redis.get(key) para confirmar presenÃ§a do valor
```

---

## ğŸ”§ Boas PrÃ¡ticas

* Utilize cache apenas em rotas idempotentes (`GET`) e com resultados relativamente estÃ¡ticos.
* Configure TTL apropriado para cada tipo de dado (exemplo: previsÃ£o do tempo em 30 minutos, geocodificaÃ§Ã£o em 24 horas).
* Garanta que as chaves sejam determinÃ­sticas e Ãºnicas por parÃ¢metros para evitar colisÃµes e inconsistÃªncias.

\*Â **TTLÂ adequado**Â â†’Â previsÃ£oÂ doÂ tempoÂ 30Â min;Â geocodificaÃ§Ã£oÂ 24Â h;Â rankingsÂ deÂ eventosÂ 5â€“30Â s.
\*Â **ChaveÂ determinÃ­stica**Â â†’Â `prefix`Â +Â `hash(args,Â kwargs)`Â â€“Â minimizaÂ colisÃµesÂ eÂ simplificaÂ invalidar.
\*Â **FallbackÂ gracioso**Â â†’Â SeÂ RedisÂ cair,Â oÂ decoratorÂ sÃ³Â ignoraÂ oÂ cache.
\*Â **SerializaÃ§Ã£oÂ Ãºnica**Â â†’Â SempreÂ JSONÂ stringÂ (`default=str`)Â paraÂ uniformidade.

---

ğŸ“¦ Onde o Redis â€œviveâ€ â€“ antes Ã— depois
CenÃ¡rio	Onde estÃ¡ o binÃ¡rio redis-server?	Como o FastAPI se conecta?	Como Ã© iniciado/parado?
Antes (dev local)	Instalado na mÃ¡quina host via brew, apt, chocoâ€¦	tcp://localhost:6379
(loopback da prÃ³pria mÃ¡quina)	redis-server rodava como processo separado/serviÃ§o do SO (systemd, serviÃ§o do Windows) â€“ vocÃª mesmo ligava/desligava.
Depois (Docker Compose)	Dentro de um container chamado redis (imagem redis:7-alpine)	tcp://redis:6379
(nome-DNS do serviÃ§o na rede Docker)	docker compose up cria outro processo isolado no container; down remove. Uptime, logs e rede gerenciados pelo Docker.

Em ambos os casos o Redis Ã© sempre um servidor prÃ³prio, 100 % fora
do processo Python. NÃ£o Ã© â€œoutra threadâ€ do FastAPI â€“ Ã© um executÃ¡vel C que
escuta numa porta TCP.

1. Como era o fluxo â€œsem containerâ€
bash
Copiar
Editar
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” 1) requer /local_info
â”‚ Navegador â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
                            â”‚     2) chama decorator
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    FastAPI  (processo)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ 3) socket TCP 127.0.0.1:6379
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ redis-server â”‚  (processo do host, fora do docker)
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
InstalaÃ§Ã£o manual â€“ brew install redis

Iniciado em background (brew services start redis)

FastAPI resolve localhost, abre um socket, fala RESP.

2. Como ficou â€œcom Docker Composeâ€
markdown
Copiar
Editar
                           (rede Docker: backend)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â–²
â”‚ Navegador â”‚â”€â”€â–º 0.0.0.0:8000 â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       host-network                       CONTAINERS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
             â”‚                        â”‚
             â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  api service   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚  redis service  â”‚
    â”‚ (fastapi:8000) â”‚ TCP   â”‚ (redis:6379)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Imagem oficial â€“ redis:7-alpine

Declarado em docker-compose.yml.

O Docker cria uma bridge network (backend).

Cada serviÃ§o recebe um hostname â€“ aqui api e redis.

O FastAPI acessa redis:6379 (DNS interno).

Logs, restart-policy, snapshot-volume podem ser configurados no YAML.

3. O que nÃ£o mudou
Componente	Antes	Depois
Biblioteca cliente	redis.asyncio	igual
FunÃ§Ã£o provide_redis()	lÃª REDIS_URL	igual (agora redis://redis:6379/0)
Decorators/cache	@cached_json	idÃªntico
CÃ³digo das rotas	nada a tocar	nada a tocar

Ou seja: sÃ³ deslocamos o servidor do â€œhostâ€ para â€œcontainerâ€, trocando
localhost por redis na URL â€“ o restante continua transparente.

4. Por que containerizar Ã© melhor
Reprodutibilidade â€“ qualquer mÃ¡quina com Docker sobe a stack
completa; nÃ£o hÃ¡ â€œfunciona-na-minha-mÃ¡quinaâ€.

Isolamento â€“ libs do Redis nÃ£o â€œpoluemâ€ o host; porta 6379 nÃ£o
fica escancarada para todo o PC se vocÃª nÃ£o quiser.

OrquestraÃ§Ã£o â€“ depends_on garante que o backend sÃ³ inicie apÃ³s
o Redis passar no healthcheck (redis-cli ping).

Escalabilidade â€“ em produÃ§Ã£o vocÃª pode ter mÃºltiplos containers
FastAPI todos usando o mesmo Redis, ou migrar para ElastiCache sem
alterar o Compose da API.

5. Pergunta frequente
â€œEntÃ£o o Redis estÃ¡ em outro processo, mas dentro da mesma VM/PC?â€
Sim. Container = processo isolado com FS prÃ³prio, mas usa o mesmo kernel
do host. Para a aplicaÃ§Ã£o isso parece â€œum servidor remotoâ€ acessÃ­vel por IP
privado.

TL;DR
Sempre foi um serviÃ§o separado; nunca uma thread Python.

No dev antigo, rodava como daemon do sistema â†’ localhost.

Agora roda num container Redis â†’ hostname redis dentro da rede Docker.

CÃ³digo Python unchanged; apenas REDIS_URL aponta para o novo host.

---

[â¬…ï¸ Voltar para o inÃ­cio](../README.md)

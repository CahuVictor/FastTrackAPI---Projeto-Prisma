# üöÄ Cache Redis para Melhor Desempenho

Este documento explica como o projeto **FastTrackAPI** utiliza o Redis para melhorar o desempenho e reduzir a lat√™ncia de algumas requisi√ß√µes HTTP, com detalhes sobre implementa√ß√£o, funcionamento local e em container, testes e boas pr√°ticas.

---

## üîÑ Vis√£o Geral

Utilizamos o padr√£o **cache-aside (lazy loading)**: o sistema tenta obter o resultado do Redis antes de consultar servi√ßos externos ou realizar c√°lculos custosos. Se o valor n√£o estiver no cache (MISS), ele √© computado, armazenado no Redis e retornado.

| Fluxo da requisi√ß√£o        | Sem cache                          | Com cache Redis (cache-aside)                                          |
| -------------------------- | ---------------------------------- | ---------------------------------------------------------------------- |
| Execu√ß√£o                   | FastAPI ‚Üí Servi√ßo ‚Üí DB/API externa | FastAPI ‚Üí **Redis GET** ‚Üí HIT ‚úî (retorno r√°pido) / MISS ‚úñ ‚Üí Servi√ßo ‚Üí Redis SETEX ‚Üí Cliente |
| Lat√™ncia m√©dia             | 400ms - 2s                         | 1ms - 5ms (ap√≥s primeiro MISS)                                         |
| Carga externa              | 100% das requisi√ß√µes               | 1 requisi√ß√£o por TTL                                                   |

> **Estrat√©gia**: *cache‚Äëaside* (tamb√©m chamado *lazy loading*) ‚Äì apenas grava no Redis depois de consultar a fonte correta.

---

## ‚öôÔ∏è Implementa√ß√£o no C√≥digo

| Camada                 | Arquivo / Elemento                              | Descri√ß√£o                                                                                              |
| ---------------------- | ----------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| **Provider**           | `app/deps.py ‚Üí provide_redis()`                 | Cria **uma √∫nica** inst√¢ncia `Redis.from_url(..)` e a reaproveita em todo o app                        |
| **Decorator gen√©rico** | `app/utils/cache.py ‚Üí cached_json()`            | Fun√ß√£o ass√≠ncrona que gera chave, consulta Redis (`GET`), serializa JSON (`SETEX`) e devolve resultado |
| **Aplica√ß√£o real**     | `app/api/v1/endpoints/eventos.py`, entre outros | Endpoints decorados com `@cached_json("prefix", ttl)`                                                  |
| **Configura√ß√£o**       | `.env / config.py ‚Üí REDIS_URL`                  | Permite apontar para Redis local, Docker, ou nuvem  

### Decorador Gen√©rico

Utilizamos o decorador `cached_json` que automatiza o uso do cache Redis com as seguintes etapas:

1. Gera√ß√£o de chave √∫nica com base nos par√¢metros da requisi√ß√£o.
2. Verifica√ß√£o no Redis via `GET`.
3. Se n√£o encontrar (MISS), executa a fun√ß√£o original e armazena o resultado com `SETEX`.
4. Retorna o valor ao cliente.

Internamente, usamos `jsonable_encoder()` para garantir que o valor armazenado seja serializ√°vel e compat√≠vel com `response_model`.

Exemplo no c√≥digo:

```python
@cached_json("local-info", ttl=86400)
async def obter_local_info(location_name: str, service: AbstractLocalInfoService = Depends(provide_local_info_service)):
    info = await service.get_by_name(location_name)
    if info is None:
        raise HTTPException(404, "Local n√£o encontrado")
    return info
```

#### Corre√ß√£o de serializa√ß√£o

A serializa√ß√£o usa agora `jsonable_encoder` para transformar objetos Pydantic e tipos n√£o-serializ√°veis:

```python
from fastapi.encoders import jsonable_encoder

serializable = jsonable_encoder(result)
await redis.setex(key, ttl, json.dumps(serializable))
```

E a leitura usa:

```python
cached = json.loads(raw)
return cached
```

##### üîÑ Patch atual do decorador `cached_json`

```python
try:
    if (raw := await redis.get(key)):
        logger.info("Cache hit", key=key)
        return json.loads(raw)

    logger.debug("Cache miss", key=key)
    result = await func(*args, **kwargs)
    serializable = jsonable_encoder(result)
    await redis.setex(key, ttl, json.dumps(serializable))
    return serializable
except Exception as e:
    logger.warning("Erro ao acessar o cache Redis", error=str(e))
    return await func(*args, **kwargs)
```

Removemos `default=str`, que convertia objetos em string literal e causava `ResponseValidationError` ao retornar do cache.

#### Gera√ß√£o de chave determin√≠stica

Ignoramos objetos como `repo`, `request`, `Session`, etc., ao construir a chave:

```python
SAFE_TYPES = (str, int, float, bool, type(None))
clean = {k: v for k, v in bound_args.items() if isinstance(v, SAFE_TYPES)}
key = prefix + ":" + str(hash(tuple(sorted(clean.items()))))
```

Evita que inst√¢ncias injetadas pelo FastAPI causem cache miss constante.

---

## üìç Onde o Cache √© Usado

| Endpoint                              | Prefixo / TTL      | Motivo                                           |
| ------------------------------------- | ------------------ | ------------------------------------------------ |
| `GET /api/v1/local_info`              | `local-info` / 24h | Geocodifica√ß√£o raramente muda                    |
| `GET /api/v1/forecast_info`           | `forecast` / 30min | API de clima √© custosa e n√£o muda r√°pido         |
| `GET /api/v1/eventos/top/soon`        | `top-soon` / 10s   | Ranking √© vol√°til, mas leitura r√°pida √© valiosa  |
| `GET /api/v1/eventos/top/most-viewed` | `top-viewed` / 30s | Muda apenas com `views++`; ideal para cache leve |

| Endpoint                              | Prefixo / TTL           | Motivo do cache                                                                               | Local do c√≥digo                                        |
| ------------------------------------- | ----------------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| `GET¬†/api/v1/local_info`              | `local‚Äëinfo` / **24‚ÄØh** | Resultado de geocodifica√ß√£o √© praticamente est√°tico; evita chamadas ao servi√ßo externo.       | `app/api/v1/endpoints/eventos.py`¬†‚Üí¬†`obter_local_info` |
| `GET¬†/api/v1/forecast_info`           | `forecast` / **30‚ÄØmin** | Chamada mockada mas, em produ√ß√£o, seria a API de clima (lenta/paga).                          | Mesmo arquivo¬†‚Üí¬†`obter_forecast_info`                  |
| `GET¬†/api/v1/eventos/top/soon`        | `top‚Äësoon` / **10‚ÄØs**   | Ranking de "pr√≥ximos N" muda a cada poucos segundos; snapshot ultra‚Äëcurto j√° satisfaz.        | Mesmo arquivo¬†‚Üí¬†`eventos_proximos`                     |
| `GET¬†/api/v1/eventos/top/most-viewed` | `top‚Äëviewed` / **30‚ÄØs** | Ranking de mais vistos muda s√≥ quando views incrementa; 30¬†s equilibra frescor √ó performance. | Mesmo arquivo¬†‚Üí¬†`eventos_mais_vistos`                  |

Cada fun√ß√£o √© decorada com `@cached_json(<prefix>, ttl=<segundos>)`, implementado em **`app/utils/cache.py`**, que:

1. Gera uma chave determin√≠stica com prefixo + params;
2. Faz `await redis.get(key)` ‚Üí **HIT** devolve JSON;
3. **MISS** executa a fun√ß√£o real, serializa e grava `SETEX key ttl value`.

---

## ‚ö†Ô∏è Quando N√£o Usar Cache

| Raz√£o                  | Justificativa                                                                    |
| ---------------------- | -------------------------------------------------------------------------------- |
| **N√£o idempotente**    | `POST`, `PUT`, `DELETE` alteram estado e n√£o devem ser cacheados.                |
| **Alta cardinalidade** | Muitos par√¢metros geram muitas combina√ß√µes de chave (explos√£o de cache).         |
| **Dados vol√°teis**     | Quando o dado muda mais r√°pido do que o TTL poss√≠vel.                            |
| **Privacidade**        | Respostas espec√≠ficas por usu√°rio n√£o devem ser compartilhadas em cache an√¥nimo. |

> Regra pr√°tica: cache apenas `GET`s idempotentes com acesso frequente e custo computacional alto.

---

## ‚úÖ Benef√≠cios

* **Redu√ß√£o dr√°stica na lat√™ncia:** Requisi√ß√µes comuns passam a ser respondidas em milissegundos.
* **Menor carga em servi√ßos externos:** Reduz a frequ√™ncia de chamadas custosas a APIs externas.
* **Escalabilidade facilitada:** Redis pode ser facilmente substitu√≠do por servi√ßos gerenciados como AWS ElastiCache sem altera√ß√£o no c√≥digo.
* **Alta disponibilidade:** Caso o Redis falhe, o sistema continua funcionando normalmente, apenas ignorando o cache.

---

## üóÉÔ∏è Configura√ß√£o do Redis

A vari√°vel `REDIS_URL` no `.env` define a URL de conex√£o, permitindo trocar de ambiente facilmente:

```ini
# .env (desenvolvimento local)
REDIS_URL=redis://localhost:6379/0

# .env.prod (ambiente com container)
REDIS_URL=redis://redis:6379/0
```

---

## ‚òëÔ∏è Checar Fun√ß√£o de Gera√ß√£o de Key

A fun√ß√£o de gera√ß√£o de chave utilizava todos os argumentos, incluindo objetos n√£o serializ√°veis como reposit√≥rios, sessions, etc. Isso fazia com que o `hash()` resultasse em valores diferentes para chamadas id√™nticas.

### ‚úÖ Solu√ß√£o

**Evite tipos n√£o determin√≠sticos na key:**

```python
def _make_key(prefix: str, bound_args: dict) -> str:
    SAFE_TYPES = (str, int, float, bool, type(None))
    clean = {k: v for k, v in bound_args.items() if isinstance(v, SAFE_TYPES)}
    return prefix + ":" + str(hash(tuple(sorted(clean.items()))))
```

Use no wrapper:

```python
bound = sig.bind_partial(*args, **kwargs)
bound.apply_defaults()
key = _make_key(prefix, bound.arguments)
```

### Vers√£o parametriz√°vel (include)

```python
def cached_json(prefix: str, ttl: int = 60, include: set[str] | None = None):
    ...
        key_args = {k: v for k, v in bound.arguments.items()
                    if (include and k in include) or
                       (include is None and isinstance(v, SAFE_TYPES))}
        key = _make_key(prefix, key_args)
```

No endpoint:

```python
@cached_json("top-soon", ttl=10, include={"limit"})
```

### Serializa√ß√£o correta do resultado

Em vez de usar `json.dumps(result, default=str)`, serialize com:

```python
from fastapi.encoders import jsonable_encoder
serializable = jsonable_encoder(result)
await redis.setex(key, ttl, json.dumps(serializable))
```

No cache hit:

```python
return json.loads(raw)
```

Evita erros como `ResponseValidationError` por strings onde o FastAPI espera dicion√°rios.

---

## üî™ Instala√ß√£o (Desenvolvimento Local com Windows)

### 1. Instala√ß√£o via Chocolatey

```powershell
choco install redis-64 -y
```

Esse comando instala o Memurai Developer (Redis compat√≠vel com Windows) e registra um servi√ßo do Windows.

### 2. Controlar o servi√ßo Redis (Memurai)

```powershell
Get-Service Memurai          # verificar status
Start-Service Memurai        # iniciar
Stop-Service Memurai         # parar
Set-Service Memurai -StartupType Automatic
```

### 2.1 Controlar o servi√ßo Redis (Redis)

```powershell
Get-Service Redis            # verificar status
Start-Service Redis          # iniciar
Stop-Service  Redis          # parar
Set-Service   Redis -StartupType Automatic  # (ou Manual, Disabled‚Ä¶)
```

### 3. Executar manualmente (sem servi√ßo)

```powershell
"C:\Program Files\Memurai\memurai.exe" --port 6379
```

Mant√©m a janela aberta ou use NSSM para rodar em background.

### 4. Testar se o Redis responde

```powershell
"C:\Program Files\Memurai\redis-cli.exe" -p 6379 ping
# deve responder: PONG
```

### 5. Verificar porta (opcional)

```powershell
netstat -ano | findstr ":6379"
```

### 6. Verifica√ß√£o no .env

```ini
REDIS_URL=redis://localhost:6379/0
```

Suba a API normalmente e verifique os logs:

* Primeira requisi√ß√£o: `MISS`
* Segunda requisi√ß√£o: `HIT`

### 7. Erros

#### Liberar locks quebrados
```powershell
# pare qualquer tarefa Chocolatey em background
Stop-Process -Name "choco*" -Force -ErrorAction SilentlyContinue
```

#### remova lock e pasta corrompida
```powershell
Remove-Item -Force -Recurse "C:\ProgramData\chocolatey\lib\9daa46124c4f3ddfd7a43a5d893196d2767a7cf7" -ErrorAction SilentlyContinue
Remove-Item -Force -Recurse "C:\ProgramData\chocolatey\lib-bad" -ErrorAction SilentlyContinue
(Se o primeiro caminho n√£o existir mais, ignore o erro.)
```

---

## üß™ Testes com Cache

| Caso de Teste        | Objetivo                                                      | Ferramenta sugerida             |
| -------------------- | ------------------------------------------------------------- | ------------------------------- |
| **HIT vs MISS**      | Verificar se a resposta vem do cache ap√≥s primeira requisi√ß√£o | `fakeredis`, `pytest`           |
| **Expira√ß√£o de TTL** | Confirmar renova√ß√£o ap√≥s TTL                                  | `time.sleep`, `freezegun`       |
| **Chaves √∫nicas**    | Garantir que chaves s√£o determin√≠sticas                       | `redis.keys()`                  |
| **Falha do Redis**   | Verificar fallback se Redis estiver indispon√≠vel              | Mock/patch de `provide_redis()` |

Exemplo:

```python
from fastapi.encoders import jsonable_encoder

@cached_json("top-soon", ttl=10, include={"limit"})
async def eventos_proximos(limit: int = 5):
    ...
```

> Use `fakeredis.FakeRedis()` em testes para isolar depend√™ncia externa.

---

## üîß Boas Pr√°ticas

* Cache apenas rotas `GET` e com resultados relativamente est√°ticos.
* TTLs adaptados √† natureza do dado (ex: 30s para ranking, 24h para dados est√°ticos).
* Sempre use `jsonable_encoder` antes de serializar com `json.dumps`.
* Gere chaves com base apenas em args simples
* Permita fallback (try/except no acesso Redis)

---

## üß± Redis: Funcionamento Local vs Container

### Por que Redis √© externo?

O Redis √© **um servi√ßo separado**, n√£o √© parte do c√≥digo Python. A aplica√ß√£o apenas se conecta a ele por meio da biblioteca `redis.asyncio`.

Colocar o Redis dentro da pr√≥pria API faria com que ele morresse e reiniciasse a cada deploy, al√©m de perder os dados. Por isso, ele roda como processo separado ou container.

### üì¶ Onde o Redis "vive"

| Cen√°rio        | Bin√°rio redis-server       | Conex√£o FastAPI        | Iniciado via                   |
| -------------- | -------------------------- | ---------------------- | ------------------------------ |
| Dev Local      | Instalado via choco/brew   | `tcp://localhost:6379` | Servi√ßo do sistema ou terminal |
| Docker Compose | Container `redis:7-alpine` | `tcp://redis:6379`     | `docker compose up`            |

Ambos os casos: o Redis √© **um servidor real**, escutando em uma porta TCP. N√£o √© uma thread nem subprocesso da API.

### 1. Fluxo sem container

```bash
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê 1) requisi√ß√£o
‚îÇ Navegador ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
                            ‚îÇ     2) FastAPI usa cache
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ    FastAPI (processo)      ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ 3) socket TCP para 127.0.0.1:6379
                              ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ redis-server ‚îÇ (servi√ßo no host)
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2. Fluxo com Docker Compose

```
                           (rede Docker: backend)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚ñ≤
‚îÇ Navegador ‚îÇ‚îÄ‚îÄ‚ñ∫ 0.0.0.0:8000 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       host-network                       CONTAINERS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             ‚îÇ                        ‚îÇ
             ‚ñº                        ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  api service   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  redis service  ‚îÇ
    ‚îÇ (fastapi:8000) ‚îÇ TCP   ‚îÇ (redis:6379)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

* O Docker cria uma rede bridge e atribui hostnames.
* A URL redis\://redis:6379/0 aponta para o servi√ßo Redis.
* Compose permite configurar restart, volumes e logs.

### 3. O que n√£o mudou

| Componente               | Antes (host)           | Depois (container) |
| ------------------------ | ---------------------- | ------------------ |
| Cliente Redis            | `redis.asyncio`        | igual              |
| Fun√ß√£o `provide_redis()` | REDIS\_URL (localhost) | REDIS\_URL (redis) |
| Decorator/cache          | `@cached_json`         | igual              |
| C√≥digo das rotas         | nada a mudar           | nada a mudar       |

### 4. Vantagens do container

* ‚úÖ Reprodutibilidade: stack sobe com `docker compose up`.
* ‚úÖ Isolamento: Redis n√£o polui o sistema operacional.
* ‚úÖ Orquestra√ß√£o: `depends_on`, healthcheck etc.
* ‚úÖ Escalabilidade: f√°cil migrar para Redis gerenciado (ElastiCache etc.).

### 5. Pergunta frequente

**‚ÄúO Redis est√° em outro processo?‚Äù**

> Sim. Seja local ou container, o Redis sempre roda em processo separado da API. FastAPI se conecta via TCP (localhost ou rede Docker).

---

‚úÖ **TL;DR**: O Redis √© um cache externo, operado fora da API. No desenvolvimento, pode rodar localmente como servi√ßo do sistema. Em produ√ß√£o, containerizado, com o mesmo cliente e sem alterar o c√≥digo. A chave para funcionar √© ajustar corretamente a vari√°vel `REDIS_URL`.

---

## ü§ñ Redis: Local vs Container

| Cen√°rio            | Execut√°vel Redis                 | URL usada                  | Inicializa√ß√£o                      |
| ------------------ | -------------------------------- | -------------------------- | ---------------------------------- |
| **Antes** (local)  | `redis-server` no host (Memurai) | `redis://localhost:6379/0` | Manual via `Start-Service Memurai` |
| **Agora** (Docker) | container `redis:7-alpine`       | `redis://redis:6379/0`     | `docker-compose up`                |

Redis √© sempre um processo separado (nunca uma thread Python).

---

## ‚öôÔ∏è Trocar Redis por outro cache

1. Implemente `provide_memcached()` ou similar
2. Altere `cached_json` para usar outro client
3. N√£o √© necess√°rio alterar nenhum endpoint

---

---

---

## Checar fun√ß√£o de gerar a key

O motivo cl√°ssico - e o seu c√≥digo confirma - √© que a fun√ß√£o que gera a key
est√° incluindo objetos mut√°veis/√∫nicos (por ex. o reposit√≥rio repo,
Session, etc.) nos args/kwargs.

python
Copiar
Editar
key = prefix + ":" + str(hash((args, tuple(sorted(kwargs.items())))))
Cada vez que FastAPI injeta repo, ele √© uma nova inst√¢ncia
(<SQLEventRepo object at 0x...>).

O hash() desses objetos muda ‚Üí a chave muda ‚Üí MISS sempre.

1 ‚Äî Verifique no log
Adicione, s√≥ para depurar, o valor da chave:

python
Copiar
Editar
logger.debug("Cache key", prefix=prefix, key=key)
Voc√™ ver√° algo como:

python-repl
Copiar
Editar
... key=top-soon:123456789
... key=top-soon:-987654321   # outra chamada ‚Üí outra key
2 ‚Äî Corrija a fun√ß√£o de gera√ß√£o de chave
Abordagem simples: ignore par√¢metros n√£o cache√°veis
python
Copiar
Editar
def _make_key(prefix: str, bound_args: dict) -> str:
    SAFE_TYPES = (str, int, float, bool, type(None))
    clean = {k: v for k, v in bound_args.items() if isinstance(v, SAFE_TYPES)}
    return prefix + ":" + str(hash(tuple(sorted(clean.items()))))
E no wrapper:

python
Copiar
Editar
bound = sig.bind_partial(*args, **kwargs)
bound.apply_defaults()
key = _make_key(prefix, bound.arguments)
N√£o entram repo, service, request, nem qualquer objeto n√£o
serializ√°vel.

Abordagem parametriz√°vel
Se quiser algo mais expl√≠cito:

python
Copiar
Editar
def cached_json(prefix: str, ttl: int = 60, include: set[str] | None = None):
    ...
        key_args = {k: v for k, v in bound.arguments.items()
                    if (include and k in include) or
                       (include is None and isinstance(v, SAFE_TYPES))}
        key = _make_key(prefix, key_args)
Ent√£o no endpoint:

python
Copiar
Editar
@cached_json("top-soon", ttl=10, include={"limit"})

üí° O que ocorreu
Primeira requisi√ß√£o ‚Äì cache miss

FastAPI devolve uma lista de objetos Pydantic (EventResponse).

No decorator voc√™ faz

python
Copiar
Editar
json.dumps(result, default=str)
Como EventResponse n√£o √© JSON-serializ√°vel, o default=str converte
cada objeto em string (a representa√ß√£o title='Evento 1' ...).

Segunda requisi√ß√£o ‚Äì cache hit

Voc√™ l√™ o valor, faz json.loads(...) ‚Üí volta uma lista de strings.

FastAPI tenta validar contra response_model=list[EventResponse]
‚Üí v√™ string, n√£o dicion√°rio ‚Üí levanta 10 erros ‚ÄúInput should be a valid
dictionary ‚Ä¶‚Äù.

üõ†Ô∏è Corre√ß√£o
Armazene no Redis um payload j√° serializado via
fastapi.encoders.jsonable_encoder, que transforma Pydantic, datetime,
Enum etc. em tipos puros JSON (dict, list, str, int).

python
Copiar
Editar
from fastapi.encoders import jsonable_encoder

...

serializable = jsonable_encoder(result)
await redis_client.setex(key, ttl, json.dumps(serializable))
return serializable      # devolve dict/list; FastAPI validar√° OK
E no cache hit basta:

python
Copiar
Editar
cached = json.loads(raw)
return cached            # FastAPI monta de volta o EventResponse
Patch completo (trecho do wrapper)
python
Copiar
Editar
try:
    if (raw := await redis_client.get(key)):
        logger.info("Cache hit", prefix=prefix, key=key)
        return json.loads(raw)

    logger.debug("Cache miss", prefix=prefix, key=key)
    result: T = await func(*args, **kwargs)

    serializable = jsonable_encoder(result)
    await redis_client.setex(key, ttl, json.dumps(serializable))
    logger.debug("Valor armazenado no cache", prefix=prefix, key=key, ttl=ttl)
    return serializable
Importante: remova default=str do json.dumps; ele ‚Äúamassa‚Äù objetos
em string e perde estrutura.

---

[‚¨ÖÔ∏è Voltar para o README](../README.md)
